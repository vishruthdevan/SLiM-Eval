{
  "model": "google/gemma-3-4b-it",
  "precision": "fp16",
  "quantization_scheme": "FP16",
  "timestamp": "2025-12-09T15:51:19.013097",
  "num_parameters": 4300000000,
  "num_parameters_b": 4.3,
  "model_size_gb": 8.64,
  "_note": "Parameter values estimated from official model file size (8.64 GB BF16). llmcompressor/vllm limitations prevented experimental measurement for Gemma 3.",
  "mean_latency_s": 0.2597755591869354,
  "median_latency_s": 0.2600066661834717,
  "p95_latency_s": 0.2616434693336487,
  "p99_latency_s": 0.28931403160095215,
  "std_latency_s": 0.006166607160500928,
  "mean_peak_mem_mb": 74380.625,
  "mean_avg_mem_mb": 74382.625,
  "tokens_per_second": 966.1878922927667
}