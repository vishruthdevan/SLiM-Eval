model,precision,quantization_scheme,timestamp,num_parameters,num_parameters_b,size_gb_fp16,mean_latency_s,median_latency_s,p95_latency_s,p99_latency_s,std_latency_s,mean_peak_mem_mb,mean_avg_mem_mb,tokens_per_second,energy_kwh,energy_joules,duration_seconds,avg_power_watts,min_power_watts,max_power_watts,std_power_watts,energy_per_query_j,mmlu_accuracy,gsm8k_accuracy,hellaswag_accuracy
meta-llama/Llama-3.2-3B-Instruct,fp16,FP16,2025-12-08T15:36:45.355083,3958898688,3.958898688,7.3740234375,0.3800024462938309,0.3783564269542694,0.3802109956741333,0.5010114908218384,0.013365489278818666,969.75,972.878,673.679873634424,0.0048516020004357625,17465.767201568746,572.5046124458313,30.50764451827243,17.337,68.968,21.69534569429461,87.32883600784373,0,0,0
meta-llama/Llama-3.2-3B-Instruct,int8,SmoothQuant+GPTQ (W8A8),2025-12-08T17:33:09.252077,3958898688,3.958898688,7.3740234375,0.22912280535697938,0.22818142175674438,0.2290424406528473,0.3021220366160075,0.00805480132551031,5707.74658203125,45779.0625,964.5482458879471,0.028101010186519983,101163.63667147193,398.02212738990784,254.16586091549294,216.585,256.216,2.1378898205544994,505.81818335735966,,,
meta-llama/Llama-3.2-3B-Instruct,int4,SmoothQuant+GPTQ (W4A16),2025-12-08T18:16:24.658076,3958898688,3.958898688,7.3740234375,0.17455008196830749,0.17357167601585388,0.17578470706939697,0.2276402711868286,0.005917523039049252,4444.88916015625,45733.0625,1466.6277844915658,0.01728767995301766,62235.64783086358,216.19941806793213,287.86223564814816,237.365,292.057,4.328326377067052,311.1782391543179,,,
