watch -n 1 nvidia-smi

export HF_HOME="/mnt/swordfish-pool2/kavin/cache"
export CUDA_VISIBLE_DEVICES="3"

echo $HF_HOME
echo $CUDA_VISIBLE_DEVICES

slim-eval run --models meta-llama/Llama-3.2-3B-Instruct --precision fp16 --accuracy-batch-size-mmlu 1 --max-model-len 8192
slim-eval run --models meta-llama/Llama-3.2-3B-Instruct --precision int8 --accuracy-batch-size-mmlu 1 -—max-model-len 8192
slim-eval run --models meta-llama/Llama-3.2-3B-Instruct --precision int4 --accuracy-batch-size-mmlu 1 -—max-model-len 8192

slim-eval run --models meta-llama/Llama-3.2-3B-Instruct --precision int8 -—max-model-len 8192

slim-eval run --models meta-llama/Llama-3.2-3B-Instruct --precision fp16 --accuracy-batch-size-mmlu 1 --max-model-len 8192 --gpu-index 0

slim-eval run --models meta-llama/Llama-3.2-3B-Instruct --precision int8 --tasks "energy performance" --max-model-len 8192 --quantized-models-dir /mnt/swordfish-pool2/kavin/slimeval/quantized_models
slim-eval run --models meta-llama/Llama-3.2-3B-Instruct --precision int4 --tasks "energy performance" --max-model-len 8192 --quantized-models-dir /mnt/swordfish-pool2/kavin/slimeval/quantized_models

slim-eval run \
  --models meta-llama/Llama-3.2-3B-Instruct \
  --precision int8 \
  --tasks "energy performance" \
  --max-model-len 8192 \
  --quantized-models-dir /mnt/swordfish-pool2/kavin/slimeval/quantized_models \
  --output-dir /mnt/swordfish-pool2/kavin/slimeval/outputs

slim-eval run --models meta-llama/Llama-3.2-3B-Instruct --precision int8 --tasks "energy performance" --max-model-len 8192 --quantized-models-dir /mnt/swordfish-pool2/kavin/slimeval/quantized_models --output-dir /mnt/swordfish-pool2/kavin/slimeval/outputs

// wandb
pip install wandb
wandb login
export WANDB_API_KEY="your-api-key-here"

slim-eval run \
  --models meta-llama/Llama-3.2-3B-Instruct \
  --precision fp16 \
  --tasks "energy performance" \
  --max-model-len 8192 \
  --quantized-models-dir /mnt/swordfish-pool2/kavin/slimeval/quantized_models \
  --output-dir /mnt/swordfish-pool2/kavin/slimeval/outputs \
  --wandb-enabled \
  --wandb-project slim-eval \
  --wandb-run-name "testing fp16 Llama-3.2-3B-Instruct"

// analyse
slim-eval analyze --input-dir outputs --output-dir analysis_results