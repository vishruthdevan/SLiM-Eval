{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88d28278",
   "metadata": {},
   "source": [
    "# SLiM-Eval: Complete Small Language Model Evaluation Framework\n",
    "## Tracking: Latency, Memory, Energy, and Accuracy\n",
    "\n",
    "This notebook contains:\n",
    "1. Environment setup and verification\n",
    "2. Model quantization using llm-compressor\n",
    "3. **Latency and memory** benchmarking using vLLM\n",
    "4. **Energy consumption** tracking using CodeCarbon/powermetrics\n",
    "5. **Accuracy evaluation** using lm-evaluation-harness\n",
    "6. Results analysis and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d081c583",
   "metadata": {},
   "source": [
    "## Cell 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb029d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Uncomment and run if packages are not installed\n",
    "# !pip install accelerate\n",
    "# !pip install pandas numpy tqdm\n",
    "# !pip install matplotlib seaborn\n",
    "# !pip install lm-eval>=0.4.0  # For accuracy evaluation\n",
    "# !pip install codecarbon \n",
    "\n",
    "# !pip install vllm==0.11.0\n",
    "# !pip install transformers==4.56.2\n",
    "# # # !pip install llm-compressor\n",
    "# !pip install llmcompressor\n",
    "# # !pip install bitsandbytes\n",
    "# # For energy tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1758a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40f9cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'torch==2.8.0' torchvision torchaudio --index-url https://download.pytorch.org/whl/cu129"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9174319",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0215334",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'vllm==0.11.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79166e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'transformers==4.56.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd59bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llmcompressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e639028",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'lm-eval>=0.4.0'  # For accuracy evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1e1518",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate\n",
    "!pip install pandas numpy tqdm\n",
    "!pip install matplotlib seaborn\n",
    "!pip install codecarbon # For energy tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93a516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32753b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "HF_CACHE_DIR = \"/mnt/swordfish-pool2/kavin/cache\"\n",
    "CUDA_DEVICE = \"6\"\n",
    "\n",
    "os.environ['HF_HOME'] = HF_CACHE_DIR\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = CUDA_DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a070da",
   "metadata": {},
   "source": [
    "## Cell 2: Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2476b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu129\n",
      "CUDA available: True\n",
      "GPU: NVIDIA RTX A6000\n",
      "CUDA version: 12.9\n",
      "GPU Memory: 47.40 GB\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import psutil\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from vllm import LLM, SamplingParams\n",
    "from huggingface_hub import login\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Import codecarbon for energy tracking\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "# Import lm-eval for accuracy\n",
    "from lm_eval import evaluator\n",
    "from lm_eval.models.vllm_causallms import VLLM as VLLM_LM\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(\n",
    "        f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\"\n",
    "    )\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"<HF_TOKEN>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153fef34",
   "metadata": {},
   "source": [
    "## Cell 3: Configuration - Edit This Cell to Customize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8db7fc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  Models: 1\n",
      "  Precisions: ['int8']\n",
      "  Latency runs: 100\n",
      "  Accuracy tasks: ['mmlu', 'gsm8k', 'hellaswag']\n",
      "  Energy tracking: True\n",
      "  Output directory: slim_eval_results\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EDITABLE MODEL LIST - Add or remove models as needed\n",
    "# ============================================================================\n",
    "MODELS = [\n",
    "    # \"microsoft/Phi-3-mini-4k-instruct\",  # Phi-3 3.8B\n",
    "    # \"microsoft/Phi-3.5-mini-instruct\",  # Phi-3.5 3.8B\n",
    "    # \"google/gemma-2-2b-it\",  # Gemma 2 2B\n",
    "    \"meta-llama/Llama-3.2-3B\",  # Llama 3.2 3B\n",
    "    # \"Qwen/Qwen2.5-3B-Instruct\",  # Qwen2.5 3B\n",
    "    # \"mistralai/Mistral-7B-Instruct-v0.3\",  # Mistral 7B\n",
    "]\n",
    "\n",
    "# ============================================================================\n",
    "# BENCHMARK CONFIGURATION\n",
    "# ============================================================================\n",
    "# LATENCY & MEMORY BENCHMARKING\n",
    "NUM_RUNS = 100  # Number of latency benchmark runs\n",
    "NUM_WARMUP = 10  # Warmup runs to exclude from metrics\n",
    "MAX_NEW_TOKENS = 32  # Tokens to generate per inference\n",
    "BATCH_SIZE = 32  # Batch size for vLLM (higher = faster)\n",
    "PROMPT = \"Explain one interesting fact about large language models.\"\n",
    "\n",
    "# ACCURACY EVALUATION\n",
    "ACCURACY_TASKS = [\n",
    "    \"mmlu\",  # MMLU (knowledge)\n",
    "    \"gsm8k\",  # GSM8K (math reasoning)\n",
    "    \"hellaswag\",  # HellaSwag (commonsense reasoning)\n",
    "    # \"humaneval\",       # HumanEval (code) - requires unsafe code execution\n",
    "]\n",
    "NUM_FEW_SHOT = 5  # Few-shot examples for accuracy tasks\n",
    "ACCURACY_LIMIT = None  # Set to small number (e.g., 100) for quick testing\n",
    "\n",
    "# ENERGY TRACKING\n",
    "ENABLE_ENERGY_TRACKING = True  # Enable/disable energy monitoring\n",
    "ENERGY_SAMPLE_RUNS = 100  # Number of runs for energy measurement\n",
    "\n",
    "# ============================================================================\n",
    "# QUANTIZATION PRECISIONS TO TEST\n",
    "# ============================================================================\n",
    "PRECISIONS = [\"int8\"] # [\"fp16\", \"int8\", \"int4\"]  # Can add \"gptq\", \"awq\" later\n",
    "\n",
    "# ============================================================================\n",
    "# OUTPUT CONFIGURATION\n",
    "# ============================================================================\n",
    "OUTPUT_DIR = Path(\"slim_eval_results\")\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_CSV = OUTPUT_DIR / \"complete_results.csv\"\n",
    "# QUANTIZED_MODELS_DIR = Path(\"/mnt/swordfish-pool2/kavin/slimeval/quantized_models\")\n",
    "QUANTIZED_MODELS_DIR = Path(\"/mnt/swordfish-pool2/kavin/cache\")\n",
    "QUANTIZED_MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  Models: {len(MODELS)}\")\n",
    "print(f\"  Precisions: {PRECISIONS}\")\n",
    "print(f\"  Latency runs: {NUM_RUNS}\")\n",
    "print(f\"  Accuracy tasks: {ACCURACY_TASKS}\")\n",
    "print(f\"  Energy tracking: {ENABLE_ENERGY_TRACKING}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02500a15",
   "metadata": {},
   "source": [
    "## Cell 4: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eb1e83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utility functions loaded ✓\n",
      "GPU Memory: 0.00GB allocated | 0.00GB reserved | 47.40GB total\n"
     ]
    }
   ],
   "source": [
    "def clear_cache():\n",
    "    \"\"\"Clear GPU cache and run garbage collection.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "def get_gpu_memory_mb() -> float:\n",
    "    \"\"\"Get current GPU memory usage in MB.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.memory_allocated() / (1024**2)\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def get_peak_gpu_memory_mb() -> float:\n",
    "    \"\"\"Get peak GPU memory usage in MB.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.cuda.max_memory_allocated() / (1024**2)\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "def print_gpu_memory_status():\n",
    "    \"\"\"Print current GPU memory status.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
    "        print(\n",
    "            f\"GPU Memory: {allocated:.2f}GB allocated | {reserved:.2f}GB reserved | {total:.2f}GB total\"\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"Utility functions loaded ✓\")\n",
    "print_gpu_memory_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a169881",
   "metadata": {},
   "source": [
    "## Cell 5: Quantization Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "daffb985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization configurations loaded ✓\n",
      "  - INT8: W8A8 with SmoothQuant\n",
      "  - INT4: W4A16 with SmoothQuant + GPTQ\n",
      "  - GPTQ: W4A16 GPTQ only\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from llmcompressor import oneshot\n",
    "from llmcompressor.modifiers.quantization import GPTQModifier, QuantizationModifier\n",
    "from llmcompressor.modifiers.smoothquant import SmoothQuantModifier\n",
    "from llmcompressor.utils import dispatch_for_generation\n",
    "\n",
    "# Quantization configurations\n",
    "QUANTIZATION_CONFIGS = {\n",
    "    \"int8\": {\n",
    "        \"recipe\": [\n",
    "            SmoothQuantModifier(smoothing_strength=0.8),\n",
    "            GPTQModifier(targets=\"Linear\", scheme=\"W8A8\", ignore=[\"lm_head\"]),\n",
    "        ],\n",
    "        \"method\": \"gptq_smoothquant\",\n",
    "    },\n",
    "    \"int4\": {\n",
    "        \"recipe\": [\n",
    "            SmoothQuantModifier(smoothing_strength=0.8),\n",
    "            GPTQModifier(targets=\"Linear\", scheme=\"W4A16\", ignore=[\"lm_head\"]),\n",
    "        ],\n",
    "        \"method\": \"gptq_smoothquant\",\n",
    "    },\n",
    "    \"gptq\": {\n",
    "        \"recipe\": GPTQModifier(\n",
    "            targets=\"Linear\",\n",
    "            scheme=\"W4A16\",\n",
    "            ignore=[\"lm_head\"],\n",
    "        ),\n",
    "        \"method\": \"gptq_only\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# Calibration dataset configuration\n",
    "CALIBRATION_DATASET = \"HuggingFaceH4/ultrachat_200k\"\n",
    "CALIBRATION_SPLIT = \"train_sft\"\n",
    "NUM_CALIBRATION_SAMPLES = 512\n",
    "MAX_SEQUENCE_LENGTH = 2048\n",
    "\n",
    "print(\"Quantization configurations loaded ✓\")\n",
    "print(\"  - INT8: W8A8 with SmoothQuant\")\n",
    "print(\"  - INT4: W4A16 with SmoothQuant + GPTQ\")\n",
    "print(\"  - GPTQ: W4A16 GPTQ only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3370952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "# import torch\n",
    "# from pathlib import Path\n",
    "\n",
    "# # Quantization configurations using BitsAndBytes\n",
    "# QUANTIZATION_CONFIGS = {\n",
    "#     \"int8\": {\n",
    "#         \"config\": BitsAndBytesConfig(\n",
    "#             load_in_8bit=True,\n",
    "#             llm_int8_threshold=6.0,\n",
    "#             llm_int8_has_fp16_weight=False,\n",
    "#         ),\n",
    "#         \"method\": \"bitsandbytes_int8\",\n",
    "#         \"dtype\": torch.float16,\n",
    "#     },\n",
    "#     \"int4\": {\n",
    "#         \"config\": BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_compute_dtype=torch.float16,\n",
    "#             bnb_4bit_use_double_quant=True,\n",
    "#             bnb_4bit_quant_type=\"nf4\",  # NormalFloat4 quantization\n",
    "#         ),\n",
    "#         \"method\": \"bitsandbytes_nf4\",\n",
    "#         \"dtype\": torch.float16,\n",
    "#     },\n",
    "#     \"fp16\": {\n",
    "#         \"config\": None,  # No quantization, just FP16\n",
    "#         \"method\": \"fp16_only\",\n",
    "#         \"dtype\": torch.float16,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "# print(\"Quantization configurations loaded ✓\")\n",
    "# print(\"=\" * 60)\n",
    "# print(\"Available precisions:\")\n",
    "# print(\"  - INT8: 8-bit quantization (llm_int8)\")\n",
    "# print(\"  - INT4: 4-bit NormalFloat quantization (NF4)\")\n",
    "# print(\"  - FP16: Half precision (no quantization)\")\n",
    "# print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278cffb3",
   "metadata": {},
   "source": [
    "## Cell 6: Quantization Function (Skip if using pre-quantized models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbd5e05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantization function loaded ✓\n",
      "  - Uses SmoothQuant + GPTQ for improved quality\n",
      "  - Includes generation verification\n",
      "  - Auto-handles models with/without chat templates\n"
     ]
    }
   ],
   "source": [
    "def quantize_model(model_name: str, precision: str, output_dir: Path):\n",
    "    \"\"\"Quantize a model using llm-compressor with SmoothQuant + GPTQ.\"\"\"\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"Quantizing {model_name} to {precision.upper()}\")\n",
    "    print(f\"Output: {output_dir}\")\n",
    "    print(f\"{'=' * 60}\\n\")\n",
    "\n",
    "    if output_dir.exists() and (output_dir / \"config.json\").exists():\n",
    "        print(f\"✓ Already quantized, skipping...\")\n",
    "        return\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        if precision not in QUANTIZATION_CONFIGS:\n",
    "            print(f\"✗ Unsupported precision: {precision}\")\n",
    "            return\n",
    "\n",
    "        # Load model and tokenizer\n",
    "        print(f\"Loading model and tokenizer...\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name, torch_dtype=\"auto\", device_map=\"auto\"\n",
    "        )\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "        # Load and preprocess calibration dataset\n",
    "        print(f\"Loading calibration dataset: {CALIBRATION_DATASET}\")\n",
    "        ds = load_dataset(\n",
    "            CALIBRATION_DATASET,\n",
    "            split=f\"{CALIBRATION_SPLIT}[:{NUM_CALIBRATION_SAMPLES}]\",\n",
    "        )\n",
    "        ds = ds.shuffle(seed=42)\n",
    "\n",
    "        # Preprocess with chat template (with fallback for models without chat template)\n",
    "        def preprocess(example):\n",
    "            try:\n",
    "                # Try to use chat template if available\n",
    "                return {\n",
    "                    \"text\": tokenizer.apply_chat_template(\n",
    "                        example[\"messages\"],\n",
    "                        tokenize=False,\n",
    "                    )\n",
    "                }\n",
    "            except Exception:\n",
    "                # Fallback: concatenate messages manually\n",
    "                messages = example[\"messages\"]\n",
    "                text_parts = []\n",
    "                for msg in messages:\n",
    "                    role = msg.get(\"role\", \"\")\n",
    "                    content = msg.get(\"content\", \"\")\n",
    "                    text_parts.append(f\"{role}: {content}\")\n",
    "                return {\"text\": \"\\n\".join(text_parts)}\n",
    "\n",
    "        ds = ds.map(preprocess)\n",
    "\n",
    "        # Tokenize\n",
    "        def tokenize(sample):\n",
    "            return tokenizer(\n",
    "                sample[\"text\"],\n",
    "                padding=False,\n",
    "                max_length=MAX_SEQUENCE_LENGTH,\n",
    "                truncation=True,\n",
    "                add_special_tokens=False,\n",
    "            )\n",
    "\n",
    "        ds = ds.map(tokenize, remove_columns=ds.column_names)\n",
    "\n",
    "        # Get quantization recipe\n",
    "        quant_config = QUANTIZATION_CONFIGS[precision]\n",
    "        recipe = quant_config[\"recipe\"]\n",
    "\n",
    "        print(f\"Applying quantization recipe: {quant_config['method']}\")\n",
    "\n",
    "        # Apply quantization\n",
    "        oneshot(\n",
    "            model=model,\n",
    "            dataset=ds,\n",
    "            recipe=recipe,\n",
    "            max_seq_length=MAX_SEQUENCE_LENGTH,\n",
    "            num_calibration_samples=NUM_CALIBRATION_SAMPLES,\n",
    "        )\n",
    "\n",
    "        # Verify with sample generation\n",
    "        print(\"\\n========== SAMPLE GENERATION ==============\")\n",
    "        dispatch_for_generation(model)\n",
    "        input_ids = tokenizer(\n",
    "            \"Hello my name is\", return_tensors=\"pt\"\n",
    "        ).input_ids.to(model.device)\n",
    "        output = model.generate(input_ids, max_new_tokens=50)\n",
    "        print(tokenizer.decode(output[0]))\n",
    "        print(\"==========================================\\n\")\n",
    "\n",
    "        # Save quantized model\n",
    "        print(f\"Saving to {output_dir}...\")\n",
    "        model.save_pretrained(output_dir, save_compressed=True)\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "        print(f\"✓ Quantization complete: {output_dir}\")\n",
    "\n",
    "        # Cleanup\n",
    "        del model\n",
    "        clear_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Quantization failed: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "print(\"Quantization function loaded ✓\")\n",
    "print(\"  - Uses SmoothQuant + GPTQ for improved quality\")\n",
    "print(\"  - Includes generation verification\")\n",
    "print(\"  - Auto-handles models with/without chat templates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b628340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_quantized_model(model_name, precision=\"fp16\", cache_dir=None):\n",
    "#     \"\"\"\n",
    "#     Load model with specified quantization using BitsAndBytes\n",
    "    \n",
    "#     Args:\n",
    "#         model_name: HuggingFace model identifier\n",
    "#         precision: One of \"int8\", \"int4\", \"fp16\"\n",
    "#         cache_dir: Cache directory for model storage\n",
    "    \n",
    "#     Returns:\n",
    "#         model, tokenizer\n",
    "#     \"\"\"\n",
    "#     config = QUANTIZATION_CONFIGS.get(precision)\n",
    "#     if config is None:\n",
    "#         raise ValueError(f\"Unknown precision: {precision}. Choose from {list(QUANTIZATION_CONFIGS.keys())}\")\n",
    "    \n",
    "#     print(f\"\\n{'=' * 60}\")\n",
    "#     print(f\"Loading {model_name}\")\n",
    "#     print(f\"Precision: {precision.upper()} ({config['method']})\")\n",
    "#     print(f\"{'=' * 60}\\n\")\n",
    "    \n",
    "#     try:\n",
    "#         # Load tokenizer\n",
    "#         print(\"Loading tokenizer...\")\n",
    "#         tokenizer = AutoTokenizer.from_pretrained(\n",
    "#             model_name,\n",
    "#             cache_dir=cache_dir,\n",
    "#             trust_remote_code=True\n",
    "#         )\n",
    "        \n",
    "#         # Set padding token if not set\n",
    "#         if tokenizer.pad_token is None:\n",
    "#             tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "#         print(\"✓ Tokenizer loaded\")\n",
    "        \n",
    "#         # Load model with quantization config\n",
    "#         print(f\"Loading model with {precision} quantization...\")\n",
    "#         model = AutoModelForCausalLM.from_pretrained(\n",
    "#             model_name,\n",
    "#             quantization_config=config['config'],\n",
    "#             device_map=\"auto\",\n",
    "#             torch_dtype=config['dtype'],\n",
    "#             cache_dir=cache_dir,\n",
    "#             trust_remote_code=True\n",
    "#         )\n",
    "        \n",
    "#         print(\"✓ Model loaded successfully\")\n",
    "        \n",
    "#         # Optional: Test generation to verify model works\n",
    "#         print(\"\\n========== SAMPLE GENERATION ==============\")\n",
    "#         test_input = \"Hello, my name is\"\n",
    "#         inputs = tokenizer(test_input, return_tensors=\"pt\").to(model.device)\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             outputs = model.generate(\n",
    "#                 **inputs,\n",
    "#                 max_new_tokens=20,\n",
    "#                 do_sample=False,\n",
    "#                 pad_token_id=tokenizer.eos_token_id\n",
    "#             )\n",
    "        \n",
    "#         generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#         print(f\"Input:  '{test_input}'\")\n",
    "#         print(f\"Output: '{generated_text}'\")\n",
    "#         print(\"=\" * 43 + \"\\n\")\n",
    "        \n",
    "#         return model, tokenizer\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"✗ Model loading failed: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "#         return None, None\n",
    "\n",
    "\n",
    "# def quantize_model(model_name: str, precision: str, output_dir: Path):\n",
    "#     \"\"\"\n",
    "#     Load and optionally save a quantized model.\n",
    "    \n",
    "#     Note: With BitsAndBytes, quantization happens on-the-fly during loading.\n",
    "#     This function loads the model and can save it for later use.\n",
    "#     \"\"\"\n",
    "#     print(f\"\\n{'=' * 60}\")\n",
    "#     print(f\"Processing {model_name} with {precision.upper()}\")\n",
    "#     print(f\"Output: {output_dir}\")\n",
    "#     print(f\"{'=' * 60}\\n\")\n",
    "    \n",
    "#     # Check if already processed\n",
    "#     if output_dir.exists() and (output_dir / \"config.json\").exists():\n",
    "#         print(f\"✓ Already processed, skipping...\")\n",
    "#         return\n",
    "    \n",
    "#     output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "#     # Load the quantized model\n",
    "#     model, tokenizer = load_quantized_model(model_name, precision, cache_dir=HF_CACHE_DIR)\n",
    "    \n",
    "#     if model is None:\n",
    "#         print(\"✗ Failed to load model\")\n",
    "#         return\n",
    "    \n",
    "#     # Save the model and tokenizer\n",
    "#     try:\n",
    "#         print(f\"\\nSaving to {output_dir}...\")\n",
    "#         model.save_pretrained(output_dir)\n",
    "#         tokenizer.save_pretrained(output_dir)\n",
    "#         print(f\"✓ Saved successfully: {output_dir}\\n\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"✗ Save failed: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "    \n",
    "#     finally:\n",
    "#         # Cleanup to free memory\n",
    "#         del model\n",
    "#         del tokenizer\n",
    "#         torch.cuda.empty_cache()\n",
    "#         print(\"✓ Memory cleared\")\n",
    "\n",
    "\n",
    "# print(\"=\" * 60)\n",
    "# print(\"Quantization functions loaded ✓\")\n",
    "# print(\"=\" * 60)\n",
    "# print(\"Functions available:\")\n",
    "# print(\"  - load_quantized_model(model_name, precision, cache_dir)\")\n",
    "# print(\"  - quantize_model(model_name, precision, output_dir)\")\n",
    "# print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c58fae",
   "metadata": {},
   "source": [
    "## Cell 7: vLLM Model Setup Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cea787b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model setup function loaded ✓\n",
      "  - Auto-detects pre-quantized models from llm-compressor\n",
      "  - Automatically quantizes models if not found\n",
      "  - Falls back to vLLM on-the-fly quantization if needed\n"
     ]
    }
   ],
   "source": [
    "def setup_vllm_model(\n",
    "    model_name: str, precision: str, use_quantized_dir: bool = True\n",
    ") -> Optional[LLM]:\n",
    "    \"\"\"Setup vLLM model with specified precision.\"\"\"\n",
    "    clear_cache()\n",
    "\n",
    "    try:\n",
    "        print(f\"\\n{'=' * 60}\")\n",
    "        print(f\"Loading {model_name} in {precision.upper()} precision...\")\n",
    "        print(f\"{'=' * 60}\")\n",
    "\n",
    "        if precision == \"fp16\":\n",
    "            model_path = model_name\n",
    "            dtype = \"float16\"\n",
    "            quantization = None\n",
    "        else:\n",
    "            model_short_name = model_name.split(\"/\")[-1]\n",
    "            quantized_path = QUANTIZED_MODELS_DIR / f\"{model_short_name}_{precision}\"\n",
    "\n",
    "            if use_quantized_dir and quantized_path.exists():\n",
    "                # Pre-quantized model exists\n",
    "                model_path = str(quantized_path)\n",
    "                dtype = \"auto\"\n",
    "                quantization = None  # Model is already quantized, vLLM auto-detects\n",
    "                print(f\"Using pre-quantized model from: {quantized_path}\")\n",
    "                print(f\"  Method: {QUANTIZATION_CONFIGS[precision]['method']}\")\n",
    "            elif use_quantized_dir:\n",
    "                # Pre-quantized model doesn't exist, create it\n",
    "                print(f\"Pre-quantized model not found at: {quantized_path}\")\n",
    "                print(f\"Running quantization with llm-compressor...\")\n",
    "                quantize_model(model_name, precision, quantized_path)\n",
    "                \n",
    "                # Now use the quantized model\n",
    "                if quantized_path.exists():\n",
    "                    model_path = str(quantized_path)\n",
    "                    dtype = \"auto\"\n",
    "                    quantization = None\n",
    "                    print(f\"Using newly quantized model from: {quantized_path}\")\n",
    "                else:\n",
    "                    # Quantization failed, fall back to on-the-fly\n",
    "                    print(f\"⚠️  Quantization failed, falling back to on-the-fly quantization\")\n",
    "                    model_path = model_name\n",
    "                    dtype = \"auto\"\n",
    "                    if precision == \"int8\":\n",
    "                        quantization = \"int8\"\n",
    "                    elif precision == \"int4\":\n",
    "                        quantization = \"int4\"\n",
    "                    elif precision == \"gptq\":\n",
    "                        quantization = \"gptq\"\n",
    "                    elif precision == \"awq\":\n",
    "                        quantization = \"awq\"\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unknown precision: {precision}\")\n",
    "            else:\n",
    "                # On-the-fly quantization (use_quantized_dir=False)\n",
    "                model_path = model_name\n",
    "                dtype = \"auto\"\n",
    "                print(f\"⚠️  Using base model with on-the-fly quantization: {precision}\")\n",
    "                print(f\"   For best quality, pre-quantize with llm-compressor first\")\n",
    "                \n",
    "                # Set vLLM quantization method\n",
    "                if precision == \"int8\":\n",
    "                    quantization = \"int8\"\n",
    "                elif precision == \"int4\":\n",
    "                    quantization = \"int4\"\n",
    "                elif precision == \"gptq\":\n",
    "                    quantization = \"gptq\"\n",
    "                elif precision == \"awq\":\n",
    "                    quantization = \"awq\"\n",
    "                else:\n",
    "                    raise ValueError(f\"Unknown precision: {precision}\")\n",
    "\n",
    "        llm = LLM(\n",
    "            model=model_path,\n",
    "            dtype=dtype,\n",
    "            quantization=quantization,\n",
    "            gpu_memory_utilization=0.7,\n",
    "            max_model_len=2048,\n",
    "            tensor_parallel_size=1,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "        print(f\"✓ Model loaded successfully\")\n",
    "        print_gpu_memory_status()\n",
    "        return llm\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Failed to load {model_name} in {precision}: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\"Model setup function loaded ✓\")\n",
    "print(\"  - Auto-detects pre-quantized models from llm-compressor\")\n",
    "print(\"  - Automatically quantizes models if not found\")\n",
    "print(\"  - Falls back to vLLM on-the-fly quantization if needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde46cda",
   "metadata": {},
   "source": [
    "## Cell 8: Latency & Memory Benchmarking Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bcb4bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latency/Memory benchmark function loaded ✓\n"
     ]
    }
   ],
   "source": [
    "def benchmark_latency_memory(\n",
    "    llm: LLM,\n",
    "    model_name: str,\n",
    "    precision: str,\n",
    "    num_runs: int = NUM_RUNS,\n",
    "    num_warmup: int = NUM_WARMUP,\n",
    "    batch_size: int = BATCH_SIZE,\n",
    ") -> Dict:\n",
    "    \"\"\"Benchmark vLLM model for latency and memory.\"\"\"\n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=0.0,\n",
    "        max_tokens=MAX_NEW_TOKENS,\n",
    "        top_p=1.0,\n",
    "    )\n",
    "\n",
    "    latencies = []\n",
    "    peak_memories = []\n",
    "    avg_memories = []\n",
    "    tokens_generated = []\n",
    "\n",
    "    total_iterations = (num_runs + num_warmup + batch_size - 1) // batch_size\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"LATENCY & MEMORY BENCHMARK\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Warmup: {num_warmup} | Benchmark: {num_runs} | Batch: {batch_size}\")\n",
    "\n",
    "    iteration_count = 0\n",
    "    pbar = tqdm(total=num_runs + num_warmup, desc=\"Latency/Memory\")\n",
    "\n",
    "    for batch_idx in range(total_iterations):\n",
    "        current_batch_size = min(batch_size, num_runs + num_warmup - iteration_count)\n",
    "        prompts = [PROMPT] * current_batch_size\n",
    "\n",
    "        clear_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "        start_time = time.time()\n",
    "        outputs = llm.generate(prompts, sampling_params)\n",
    "        torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "\n",
    "        batch_latency = end_time - start_time\n",
    "        peak_mem = get_peak_gpu_memory_mb()\n",
    "        avg_mem = get_gpu_memory_mb()\n",
    "        per_request_latency = batch_latency / current_batch_size\n",
    "        batch_tokens = sum(len(output.outputs[0].token_ids) for output in outputs)\n",
    "\n",
    "        for i in range(current_batch_size):\n",
    "            if iteration_count >= num_warmup:\n",
    "                latencies.append(per_request_latency)\n",
    "                peak_memories.append(peak_mem)\n",
    "                avg_memories.append(avg_mem)\n",
    "                tokens_generated.append(batch_tokens / current_batch_size)\n",
    "\n",
    "            iteration_count += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            if iteration_count >= num_runs + num_warmup:\n",
    "                break\n",
    "\n",
    "        if iteration_count >= num_runs + num_warmup:\n",
    "            break\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    lat = np.array(latencies)\n",
    "    pm = np.array(peak_memories)\n",
    "    am = np.array(avg_memories)\n",
    "    tg = np.array(tokens_generated)\n",
    "\n",
    "    results = {\n",
    "        \"mean_latency_s\": lat.mean(),\n",
    "        \"median_latency_s\": np.median(lat),\n",
    "        \"p95_latency_s\": np.percentile(lat, 95),\n",
    "        \"p99_latency_s\": np.percentile(lat, 99),\n",
    "        \"std_latency_s\": lat.std(),\n",
    "        \"mean_peak_mem_mb\": pm.mean(),\n",
    "        \"mean_avg_mem_mb\": am.mean(),\n",
    "        \"tokens_per_second\": tg.mean() / lat.mean(),\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        f\"✓ Latency: {results['mean_latency_s']:.4f}s | Memory: {results['mean_peak_mem_mb']:.2f}MB\"\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"Latency/Memory benchmark function loaded ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe564c2",
   "metadata": {},
   "source": [
    "## Cell 9: Energy Tracking Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32f70329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy benchmark function loaded ✓\n"
     ]
    }
   ],
   "source": [
    "def benchmark_energy(\n",
    "    llm: LLM,\n",
    "    model_name: str,\n",
    "    precision: str,\n",
    "    num_samples: int = ENERGY_SAMPLE_RUNS\n",
    ") -> Dict:\n",
    "    \"\"\"Measure energy consumption using CodeCarbon.\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ENERGY CONSUMPTION BENCHMARK\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Running {num_samples} inference samples with energy tracking...\")\n",
    "    \n",
    "    sampling_params = SamplingParams(\n",
    "        temperature=0.0,\n",
    "        max_tokens=MAX_NEW_TOKENS,\n",
    "        top_p=1.0,\n",
    "    )\n",
    "    \n",
    "    # Test prompts\n",
    "    test_prompts = [\n",
    "        \"Explain quantum computing in simple terms.\",\n",
    "        \"Write a Python function to calculate fibonacci numbers.\",\n",
    "        \"What are the main causes of climate change?\",\n",
    "        \"Solve: If x + 5 = 12, what is x?\",\n",
    "        \"Describe the process of photosynthesis.\",\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Create energy logs directory\n",
    "        energy_logs_dir = OUTPUT_DIR / \"energy_logs\"\n",
    "        energy_logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Initialize energy tracker\n",
    "        tracker = EmissionsTracker(\n",
    "            project_name=f\"slim_eval_{model_name.split('/')[-1]}_{precision}\",\n",
    "            output_dir=str(energy_logs_dir),\n",
    "            log_level=\"warning\",\n",
    "            save_to_file=True,\n",
    "        )\n",
    "        \n",
    "        # Start tracking\n",
    "        tracker.start()\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Run inference samples\n",
    "        for i in tqdm(range(num_samples), desc=\"Energy tracking\"):\n",
    "            prompt = test_prompts[i % len(test_prompts)]\n",
    "            prompts_batch = [prompt]\n",
    "            outputs = llm.generate(prompts_batch, sampling_params)\n",
    "        \n",
    "        # Stop tracking\n",
    "        end_time = time.time()\n",
    "        emissions = tracker.stop()\n",
    "        \n",
    "        duration = end_time - start_time\n",
    "        \n",
    "        # Handle case where emissions might be None\n",
    "        if emissions is None or emissions == 0:\n",
    "            print(\"⚠️  CodeCarbon returned no emissions data\")\n",
    "            # Provide fallback with timing only\n",
    "            results = {\n",
    "                \"energy_kwh\": 0,\n",
    "                \"energy_joules\": 0,\n",
    "                \"duration_seconds\": duration,\n",
    "                \"avg_power_watts\": 0,\n",
    "                \"num_samples\": num_samples,\n",
    "                \"energy_per_query_j\": 0,\n",
    "                \"note\": \"Energy tracking unavailable - timing only\"\n",
    "            }\n",
    "        else:\n",
    "            results = {\n",
    "                \"energy_kwh\": emissions,  # kWh\n",
    "                \"energy_joules\": emissions * 3600000,  # Convert kWh to Joules\n",
    "                \"duration_seconds\": duration,\n",
    "                \"avg_power_watts\": (emissions * 3600000 / duration) if duration > 0 else 0,\n",
    "                \"num_samples\": num_samples,\n",
    "                \"energy_per_query_j\": (emissions * 3600000 / num_samples) if num_samples > 0 else 0,\n",
    "            }\n",
    "        \n",
    "        print(f\"✓ Energy: {results['energy_kwh']*1000:.4f} Wh | Avg Power: {results['avg_power_watts']:.2f}W\")\n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Energy tracking failed: {e}\")\n",
    "        # Return fallback results with timing only\n",
    "        end_time = time.time()\n",
    "        duration = end_time - start_time if 'start_time' in locals() else 0\n",
    "        \n",
    "        return {\n",
    "            \"energy_kwh\": 0,\n",
    "            \"energy_joules\": 0,\n",
    "            \"duration_seconds\": duration,\n",
    "            \"avg_power_watts\": 0,\n",
    "            \"num_samples\": num_samples,\n",
    "            \"energy_per_query_j\": 0,\n",
    "            \"error\": str(e),\n",
    "            \"note\": \"Energy tracking failed - timing only\"\n",
    "        }\n",
    "\n",
    "print(\"Energy benchmark function loaded ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316008f9",
   "metadata": {},
   "source": [
    "## Cell 10: Accuracy Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "21e79e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy benchmark function loaded ✓\n",
      "  - Uses lm-eval with vLLM backend\n",
      "  - Supports both pre-quantized and on-the-fly quantization\n"
     ]
    }
   ],
   "source": [
    "def benchmark_accuracy(\n",
    "    model_name: str,\n",
    "    precision: str,\n",
    "    tasks: List[str] = ACCURACY_TASKS,\n",
    "    num_fewshot: int = NUM_FEW_SHOT,\n",
    "    limit: Optional[int] = ACCURACY_LIMIT,\n",
    ") -> Dict:\n",
    "    \"\"\"Evaluate model accuracy using lm-evaluation-harness with vLLM backend.\"\"\"\n",
    "\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"ACCURACY EVALUATION\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "    print(f\"Tasks: {', '.join(tasks)}\")\n",
    "    print(f\"Few-shot: {num_fewshot}\")\n",
    "    if limit:\n",
    "        print(f\"Limit: {limit} examples per task\")\n",
    "\n",
    "    try:\n",
    "        # Determine model path and arguments\n",
    "        if precision == \"fp16\":\n",
    "            model_path = model_name\n",
    "            model_args = f\"pretrained={model_path},dtype=float16,gpu_memory_utilization=0.7,max_model_len=2048,tensor_parallel_size=1\"\n",
    "        else:\n",
    "            model_short_name = model_name.split(\"/\")[-1]\n",
    "            quantized_path = QUANTIZED_MODELS_DIR / f\"{model_short_name}_{precision}\"\n",
    "            \n",
    "            # Use quantized model if it exists, otherwise use base model with quantization flag\n",
    "            if quantized_path.exists():\n",
    "                model_path = str(quantized_path)\n",
    "                print(f\"Using pre-quantized model: {model_path}\")\n",
    "            else:\n",
    "                model_path = model_name\n",
    "                print(f\"Using base model with on-the-fly quantization: {precision}\")\n",
    "            \n",
    "            # Build model arguments for vLLM\n",
    "            model_args = f\"pretrained={model_path},dtype=auto,gpu_memory_utilization=0.7,max_model_len=2048,tensor_parallel_size=1\"\n",
    "            \n",
    "            # Add quantization parameter if using base model\n",
    "            if not quantized_path.exists():\n",
    "                if precision in [\"int8\", \"int4\", \"gptq\", \"awq\"]:\n",
    "                    model_args += f\",quantization={precision}\"\n",
    "\n",
    "        # Run evaluation using lm-eval CLI-style interface\n",
    "        results = evaluator.simple_evaluate(\n",
    "            model=\"vllm\",\n",
    "            model_args=model_args,\n",
    "            tasks=tasks,\n",
    "            num_fewshot=num_fewshot,\n",
    "            batch_size=\"auto\",\n",
    "            limit=limit,\n",
    "            log_samples=False,\n",
    "        )\n",
    "\n",
    "        # Extract metrics\n",
    "        accuracy_results = {}\n",
    "        for task_name, task_results in results[\"results\"].items():\n",
    "            # Find accuracy metric (different tasks use different metric names)\n",
    "            if \"acc\" in task_results:\n",
    "                accuracy_results[f\"{task_name}_accuracy\"] = task_results[\"acc\"]\n",
    "            elif \"acc_norm\" in task_results:\n",
    "                accuracy_results[f\"{task_name}_accuracy\"] = task_results[\"acc_norm\"]\n",
    "            elif \"exact_match\" in task_results:\n",
    "                accuracy_results[f\"{task_name}_accuracy\"] = task_results[\"exact_match\"]\n",
    "            elif \"pass@1\" in task_results:\n",
    "                accuracy_results[f\"{task_name}_accuracy\"] = task_results[\"pass@1\"]\n",
    "            else:\n",
    "                # Take the first metric that looks like accuracy\n",
    "                for key, value in task_results.items():\n",
    "                    if isinstance(value, (int, float)) and 0 <= value <= 1:\n",
    "                        accuracy_results[f\"{task_name}_accuracy\"] = value\n",
    "                        break\n",
    "\n",
    "        print(f\"✓ Accuracy results:\")\n",
    "        for task, acc in accuracy_results.items():\n",
    "            print(f\"  {task}: {acc:.4f} ({acc * 100:.2f}%)\")\n",
    "\n",
    "        return accuracy_results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Accuracy evaluation failed: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return {f\"{task}_accuracy\": 0 for task in tasks}\n",
    "\n",
    "\n",
    "print(\"Accuracy benchmark function loaded ✓\")\n",
    "print(\"  - Uses lm-eval with vLLM backend\")\n",
    "print(\"  - Supports both pre-quantized and on-the-fly quantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49323013",
   "metadata": {},
   "source": [
    "## Cell 11: Main Benchmarking Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3462a9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete benchmark function loaded ✓\n"
     ]
    }
   ],
   "source": [
    "def run_complete_benchmark(model_name: str, precision: str) -> Dict:\n",
    "    \"\"\"Run complete benchmark: latency, memory, energy, and accuracy.\"\"\"\n",
    "\n",
    "    print(f\"\\n{'#' * 70}\")\n",
    "    print(f\"COMPLETE BENCHMARK: {model_name} ({precision.upper()})\")\n",
    "    print(f\"{'#' * 70}\")\n",
    "\n",
    "    results = {\n",
    "        \"model\": model_name,\n",
    "        \"precision\": precision,\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "    }\n",
    "\n",
    "    # Setup model\n",
    "    llm = setup_vllm_model(model_name, precision)\n",
    "    if llm is None:\n",
    "        print(f\"✗ Model setup failed, skipping...\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # 1. Latency & Memory\n",
    "        latency_memory_results = benchmark_latency_memory(llm, model_name, precision)\n",
    "        results.update(latency_memory_results)\n",
    "\n",
    "        # 2. Energy (if enabled)\n",
    "        if ENABLE_ENERGY_TRACKING:\n",
    "            energy_results = benchmark_energy(llm, model_name, precision)\n",
    "            results.update(energy_results)\n",
    "\n",
    "        # Clean up vLLM model before accuracy eval\n",
    "        del llm\n",
    "        clear_cache()\n",
    "        time.sleep(2)\n",
    "\n",
    "        # # 3. Accuracy\n",
    "        # accuracy_results = benchmark_accuracy(model_name, precision)\n",
    "        # results.update(accuracy_results)\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Benchmark failed: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    finally:\n",
    "        clear_cache()\n",
    "\n",
    "\n",
    "print(\"Complete benchmark function loaded ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16afb7bc",
   "metadata": {},
   "source": [
    "## Cell 12: Initialize Results CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7dfa2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Results CSV exists: slim_eval_results/complete_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Define all possible columns\n",
    "base_columns = [\n",
    "    \"model\",\n",
    "    \"precision\",\n",
    "    \"timestamp\",\n",
    "    \"mean_latency_s\",\n",
    "    \"median_latency_s\",\n",
    "    \"p95_latency_s\",\n",
    "    \"p99_latency_s\",\n",
    "    \"std_latency_s\",\n",
    "    \"mean_peak_mem_mb\",\n",
    "    \"mean_avg_mem_mb\",\n",
    "    \"tokens_per_second\",\n",
    "]\n",
    "\n",
    "energy_columns = [\n",
    "    \"energy_kwh\",\n",
    "    \"energy_joules\",\n",
    "    \"duration_seconds\",\n",
    "    \"avg_power_watts\",\n",
    "    \"energy_per_query_j\",\n",
    "]\n",
    "\n",
    "accuracy_columns = [f\"{task}_accuracy\" for task in ACCURACY_TASKS]\n",
    "\n",
    "all_columns = base_columns + energy_columns + accuracy_columns\n",
    "\n",
    "if not RESULTS_CSV.exists():\n",
    "    pd.DataFrame(columns=all_columns).to_csv(RESULTS_CSV, index=False)\n",
    "    print(f\"✓ Created results CSV: {RESULTS_CSV}\")\n",
    "else:\n",
    "    print(f\"✓ Results CSV exists: {RESULTS_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bf7088",
   "metadata": {},
   "source": [
    "## Cell 13: Run All Benchmarks\n",
    "**This cell runs everything. Will take several hours!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaf18d3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "SLiM-Eval: COMPLETE BENCHMARK SUITE\n",
      "######################################################################\n",
      "\n",
      "Models: 1\n",
      "Precisions: ['int8']\n",
      "Total configs: 1\n",
      "Metrics: Latency, Memory, Energy, Accuracy\n",
      "Output: slim_eval_results/complete_results.csv\n",
      "\n",
      "Estimated time: ~30 minutes\n",
      "\n",
      "######################################################################\n",
      "COMPLETE BENCHMARK: meta-llama/Llama-3.2-3B (INT8)\n",
      "######################################################################\n",
      "\n",
      "============================================================\n",
      "Loading meta-llama/Llama-3.2-3B in INT8 precision...\n",
      "============================================================\n",
      "Pre-quantized model not found at: /mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8\n",
      "Running quantization with llm-compressor...\n",
      "\n",
      "============================================================\n",
      "Quantizing meta-llama/Llama-3.2-3B to INT8\n",
      "Output: /mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8\n",
      "============================================================\n",
      "\n",
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56da62400ac64952a4183f825f72de25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/844 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf46bc7c94c94de3948d8997b32b08f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/20.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce1a6dcdab97432898be9e2a5a6e7ee0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907df91a66f8449c8a021605df2839b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4563a269e5c746d091d8d44b964334d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d749c16e8414bbe80a1d427e4fb8fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a84ddc9d0d74fce873aa5948ca6051e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc4b6788b0fd45f2833ca4ab169d9f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb6b79226c84ef58b54ec011378e2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2345d659f8ed4a9aaa46046926dd4ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading calibration dataset: HuggingFaceH4/ultrachat_200k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1c60f5990194d7abd78ed7f208b4024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "473d9c80f4ea4bb4b74cfe1c4c476791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_sft-00000-of-00003-a3ecf92756(…):   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "989f5d8b0b944a3a89b298aa6f458cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_sft-00001-of-00003-0a1804bcb6(…):   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f88846d485405e84d71e51a7f966fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_sft-00002-of-00003-ee46ed25cf(…):   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddf3de6e9474b4089bda218d55b9f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test_sft-00000-of-00001-f7dfac4afe5(…):   0%|          | 0.00/81.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fe61a38f3c4027b686511a0203fd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_gen-00000-of-00003-a6c9fb894b(…):   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a659fc4e6b91431aa9473b315cab213a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_gen-00001-of-00003-d6a0402e41(…):   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0947bc3633d148949f51f5279341cdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train_gen-00002-of-00003-c0db75b92a(…):   0%|          | 0.00/243M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed06422a92c846b0a90d520c19d5e5cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test_gen-00000-of-00001-3d4cd830914(…):   0%|          | 0.00/80.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4705ee3395304e728d2785485b54d68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_sft split:   0%|          | 0/207865 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1522a6899d6d456486ed4a2ea613fff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_sft split:   0%|          | 0/23110 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d929e3c9c6114f7a8f62e138464dcfe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train_gen split:   0%|          | 0/256032 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975e65c232e546e399d1c3cb8610da2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test_gen split:   0%|          | 0/28304 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efefd0d21b5c4a51b57423ffb4a5aebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1bd0bbc47448159a8956910ab65978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying quantization recipe: gptq_smoothquant\n",
      "2025-11-29T00:09:00.299504-0500 | reset | INFO - Compression lifecycle reset\n",
      "2025-11-29T00:09:00.305635-0500 | _create_default_logger | INFO - Logging all LLM Compressor modifier-level logs to sparse_logs/29-11-2025_00.09.00.log\n",
      "2025-11-29T00:09:00.307830-0500 | from_modifiers | INFO - Creating recipe from modifiers\n",
      "2025-11-29T00:09:00.308843-0500 | _infer_mappings_from_model | INFO - No SmoothQuantModifier.mappings provided, inferring from model...\n",
      "2025-11-29T00:09:00.873274-0500 | initialize | INFO - Compression lifecycle initialized for 2 modifiers\n",
      "2025-11-29T00:09:00.874115-0500 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `SmoothQuantModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Preparing cache:   0%|          | 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Preparing cache:  96%|█████████▋| 493/512 [00:01<00:00, 732.51it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Preparing cache: 100%|██████████| 512/512 [00:01<00:00, 345.15it/s]\n",
      "(1/29): Calibrating: 100%|██████████| 512/512 [00:03<00:00, 147.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:08.935719-0500 | _apply_smoothing | INFO - Smoothing with model.layers.0.input_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:09.126180-0500 | _apply_smoothing | INFO - Smoothing with model.layers.0.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 169.82it/s]\n",
      "(2/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 210.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:14.857897-0500 | _apply_smoothing | INFO - Smoothing with model.layers.1.input_layernorm\n",
      "2025-11-29T00:09:14.859454-0500 | _apply_smoothing | INFO - Smoothing with model.layers.1.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(2/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 170.41it/s]\n",
      "(3/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 213.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:20.332776-0500 | _apply_smoothing | INFO - Smoothing with model.layers.2.input_layernorm\n",
      "2025-11-29T00:09:20.334197-0500 | _apply_smoothing | INFO - Smoothing with model.layers.2.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(3/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 190.69it/s]\n",
      "(4/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 213.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:25.472747-0500 | _apply_smoothing | INFO - Smoothing with model.layers.3.input_layernorm\n",
      "2025-11-29T00:09:25.474209-0500 | _apply_smoothing | INFO - Smoothing with model.layers.3.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(4/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 187.59it/s]\n",
      "(5/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 211.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:30.682423-0500 | _apply_smoothing | INFO - Smoothing with model.layers.4.input_layernorm\n",
      "2025-11-29T00:09:30.684159-0500 | _apply_smoothing | INFO - Smoothing with model.layers.4.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(5/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.73it/s]\n",
      "(6/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 212.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:35.932587-0500 | _apply_smoothing | INFO - Smoothing with model.layers.5.input_layernorm\n",
      "2025-11-29T00:09:35.933986-0500 | _apply_smoothing | INFO - Smoothing with model.layers.5.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(6/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 193.72it/s]\n",
      "(7/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 209.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:41.081565-0500 | _apply_smoothing | INFO - Smoothing with model.layers.6.input_layernorm\n",
      "2025-11-29T00:09:41.083165-0500 | _apply_smoothing | INFO - Smoothing with model.layers.6.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(7/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 177.52it/s]\n",
      "(8/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 208.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:46.488369-0500 | _apply_smoothing | INFO - Smoothing with model.layers.7.input_layernorm\n",
      "2025-11-29T00:09:46.489774-0500 | _apply_smoothing | INFO - Smoothing with model.layers.7.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(8/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 179.43it/s]\n",
      "(9/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 209.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:51.854489-0500 | _apply_smoothing | INFO - Smoothing with model.layers.8.input_layernorm\n",
      "2025-11-29T00:09:51.855899-0500 | _apply_smoothing | INFO - Smoothing with model.layers.8.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(9/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 182.32it/s]\n",
      "(10/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 212.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:09:57.139604-0500 | _apply_smoothing | INFO - Smoothing with model.layers.9.input_layernorm\n",
      "2025-11-29T00:09:57.141157-0500 | _apply_smoothing | INFO - Smoothing with model.layers.9.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(10/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.38it/s]\n",
      "(11/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 211.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:02.408316-0500 | _apply_smoothing | INFO - Smoothing with model.layers.10.input_layernorm\n",
      "2025-11-29T00:10:02.409714-0500 | _apply_smoothing | INFO - Smoothing with model.layers.10.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(11/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.48it/s]\n",
      "(12/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 211.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:07.694501-0500 | _apply_smoothing | INFO - Smoothing with model.layers.11.input_layernorm\n",
      "2025-11-29T00:10:07.696085-0500 | _apply_smoothing | INFO - Smoothing with model.layers.11.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(12/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 188.09it/s]\n",
      "(13/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 210.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:12.917524-0500 | _apply_smoothing | INFO - Smoothing with model.layers.12.input_layernorm\n",
      "2025-11-29T00:10:12.918878-0500 | _apply_smoothing | INFO - Smoothing with model.layers.12.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(13/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 186.08it/s]\n",
      "(14/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 208.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:18.185599-0500 | _apply_smoothing | INFO - Smoothing with model.layers.13.input_layernorm\n",
      "2025-11-29T00:10:18.186992-0500 | _apply_smoothing | INFO - Smoothing with model.layers.13.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(14/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 193.63it/s]\n",
      "(15/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 209.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:23.345584-0500 | _apply_smoothing | INFO - Smoothing with model.layers.14.input_layernorm\n",
      "2025-11-29T00:10:23.347157-0500 | _apply_smoothing | INFO - Smoothing with model.layers.14.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(15/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.17it/s]\n",
      "(16/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 209.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:28.653768-0500 | _apply_smoothing | INFO - Smoothing with model.layers.15.input_layernorm\n",
      "2025-11-29T00:10:28.655492-0500 | _apply_smoothing | INFO - Smoothing with model.layers.15.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(16/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 178.24it/s]\n",
      "(17/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 207.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:34.075893-0500 | _apply_smoothing | INFO - Smoothing with model.layers.16.input_layernorm\n",
      "2025-11-29T00:10:34.077585-0500 | _apply_smoothing | INFO - Smoothing with model.layers.16.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(17/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.71it/s]\n",
      "(18/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 208.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:39.366614-0500 | _apply_smoothing | INFO - Smoothing with model.layers.17.input_layernorm\n",
      "2025-11-29T00:10:39.368111-0500 | _apply_smoothing | INFO - Smoothing with model.layers.17.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(18/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 179.16it/s]\n",
      "(19/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 205.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:44.777253-0500 | _apply_smoothing | INFO - Smoothing with model.layers.18.input_layernorm\n",
      "2025-11-29T00:10:44.778652-0500 | _apply_smoothing | INFO - Smoothing with model.layers.18.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(19/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 179.64it/s]\n",
      "(20/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 205.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:50.188046-0500 | _apply_smoothing | INFO - Smoothing with model.layers.19.input_layernorm\n",
      "2025-11-29T00:10:50.189437-0500 | _apply_smoothing | INFO - Smoothing with model.layers.19.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(20/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 176.92it/s]\n",
      "(21/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 207.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:10:55.630977-0500 | _apply_smoothing | INFO - Smoothing with model.layers.20.input_layernorm\n",
      "2025-11-29T00:10:55.632425-0500 | _apply_smoothing | INFO - Smoothing with model.layers.20.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(21/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 188.15it/s]\n",
      "(22/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 208.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:00.865707-0500 | _apply_smoothing | INFO - Smoothing with model.layers.21.input_layernorm\n",
      "2025-11-29T00:11:00.867161-0500 | _apply_smoothing | INFO - Smoothing with model.layers.21.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(22/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 188.43it/s]\n",
      "(23/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 208.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:06.104261-0500 | _apply_smoothing | INFO - Smoothing with model.layers.22.input_layernorm\n",
      "2025-11-29T00:11:06.105955-0500 | _apply_smoothing | INFO - Smoothing with model.layers.22.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(23/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.53it/s]\n",
      "(24/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 208.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:11.403853-0500 | _apply_smoothing | INFO - Smoothing with model.layers.23.input_layernorm\n",
      "2025-11-29T00:11:11.405463-0500 | _apply_smoothing | INFO - Smoothing with model.layers.23.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(24/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 182.86it/s]\n",
      "(25/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 208.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:16.729701-0500 | _apply_smoothing | INFO - Smoothing with model.layers.24.input_layernorm\n",
      "2025-11-29T00:11:16.731193-0500 | _apply_smoothing | INFO - Smoothing with model.layers.24.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(25/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 180.01it/s]\n",
      "(26/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 205.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:22.130142-0500 | _apply_smoothing | INFO - Smoothing with model.layers.25.input_layernorm\n",
      "2025-11-29T00:11:22.131646-0500 | _apply_smoothing | INFO - Smoothing with model.layers.25.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(26/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 176.41it/s]\n",
      "(27/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 205.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:27.592282-0500 | _apply_smoothing | INFO - Smoothing with model.layers.26.input_layernorm\n",
      "2025-11-29T00:11:27.593729-0500 | _apply_smoothing | INFO - Smoothing with model.layers.26.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(27/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 178.72it/s]\n",
      "(28/29): Calibrating: 100%|██████████| 512/512 [00:02<00:00, 206.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:32.997634-0500 | _apply_smoothing | INFO - Smoothing with model.layers.27.input_layernorm\n",
      "2025-11-29T00:11:32.999100-0500 | _apply_smoothing | INFO - Smoothing with model.layers.27.post_attention_layernorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(28/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 182.50it/s]\n",
      "(29/29): Calibrating: 100%|██████████| 512/512 [00:04<00:00, 110.14it/s]\n",
      "(29/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 114.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:45.261978-0500 | IndependentPipeline | INFO - Inferred `SequentialPipeline` for `GPTQModifier`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Preparing cache:   0%|          | 0/512 [00:00<?, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Preparing cache:  95%|█████████▌| 488/512 [00:00<00:00, 782.01it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Preparing cache: 100%|██████████| 512/512 [00:01<00:00, 409.91it/s]\n",
      "(1/29): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 53.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:57.298266-0500 | compress_modules | INFO - Quantizing model.layers.0.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:11:59.205550-0500 | compress | METRIC - time 1.91s\n",
      "2025-11-29T00:11:59.206501-0500 | compress | METRIC - error 61.69\n",
      "2025-11-29T00:11:59.207589-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:11:59.207932-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:11:59.208215-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:11:59.208509-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:11:59.208786-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:11:59.209057-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:11:59.209380-0500 | compress | METRIC - GPU 6 | usage: 6.09% | total memory: 51 GB\n",
      "2025-11-29T00:11:59.209694-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:11:59.210047-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:11:59.210915-0500 | compress_modules | INFO - Quantizing model.layers.0.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:12:00.253010-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:12:00.254354-0500 | compress | METRIC - error 36.91\n",
      "2025-11-29T00:12:00.254979-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:00.255290-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:00.255571-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:00.255845-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:00.256132-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:00.256397-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:00.256686-0500 | compress | METRIC - GPU 6 | usage: 6.09% | total memory: 51 GB\n",
      "2025-11-29T00:12:00.256950-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:00.257251-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:12:00.258021-0500 | compress_modules | INFO - Quantizing model.layers.0.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:12:01.321634-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:12:01.322536-0500 | compress | METRIC - error 0.13\n",
      "2025-11-29T00:12:01.323409-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:01.323812-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:01.324203-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:01.324606-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:01.325007-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:01.325390-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:01.325743-0500 | compress | METRIC - GPU 6 | usage: 6.09% | total memory: 51 GB\n",
      "2025-11-29T00:12:01.326123-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:01.326518-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:12:01.327647-0500 | compress_modules | INFO - Quantizing model.layers.0.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:12:02.375620-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:12:02.376659-0500 | compress | METRIC - error 0.02\n",
      "2025-11-29T00:12:02.377268-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:02.377560-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:02.377858-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:02.378124-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:02.378401-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:02.378674-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:02.379061-0500 | compress | METRIC - GPU 6 | usage: 6.09% | total memory: 51 GB\n",
      "2025-11-29T00:12:02.379305-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:02.379613-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:12:02.380311-0500 | compress_modules | INFO - Quantizing model.layers.0.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:12:03.488320-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:12:03.489608-0500 | compress | METRIC - error 8.31\n",
      "2025-11-29T00:12:03.490325-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:03.490627-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:03.490917-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:03.491201-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:03.491467-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:03.491747-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:03.492006-0500 | compress | METRIC - GPU 6 | usage: 6.09% | total memory: 51 GB\n",
      "2025-11-29T00:12:03.492262-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:03.492586-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:12:03.493366-0500 | compress_modules | INFO - Quantizing model.layers.0.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:12:04.607325-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:12:04.608304-0500 | compress | METRIC - error 6.28\n",
      "2025-11-29T00:12:04.609177-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:04.609486-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:04.609758-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:04.610039-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:04.610309-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:04.610582-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:04.610847-0500 | compress | METRIC - GPU 6 | usage: 6.09% | total memory: 51 GB\n",
      "2025-11-29T00:12:04.611154-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:04.611457-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:12:04.612232-0500 | compress_modules | INFO - Quantizing model.layers.0.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:12:07.543028-0500 | compress | METRIC - time 2.93s\n",
      "2025-11-29T00:12:07.544873-0500 | compress | METRIC - error 0.12\n",
      "2025-11-29T00:12:07.545540-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:07.545897-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:07.546320-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:07.546575-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:07.546850-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:07.547282-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:07.547627-0500 | compress | METRIC - GPU 6 | usage: 6.61% | total memory: 51 GB\n",
      "2025-11-29T00:12:07.547925-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:07.548279-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(1/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 172.32it/s]\n",
      "(2/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:12:20.897464-0500 | compress_modules | INFO - Quantizing model.layers.1.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:12:22.009969-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:12:22.011101-0500 | compress | METRIC - error 49.21\n",
      "2025-11-29T00:12:22.011761-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:22.012074-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:22.012406-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:22.012710-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:22.013031-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:22.013325-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:22.013623-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:22.013918-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:22.014236-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:12:22.015068-0500 | compress_modules | INFO - Quantizing model.layers.1.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:12:23.057765-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:12:23.058601-0500 | compress | METRIC - error 30.70\n",
      "2025-11-29T00:12:23.059368-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:23.059660-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:23.059962-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:23.060231-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:23.060512-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:23.060791-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:23.061076-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:23.061366-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:23.061658-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:12:23.062386-0500 | compress_modules | INFO - Quantizing model.layers.1.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:12:24.119630-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:12:24.120441-0500 | compress | METRIC - error 0.92\n",
      "2025-11-29T00:12:24.121372-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:24.121662-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:24.121958-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:24.122230-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:24.122501-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:24.122804-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:24.123099-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:24.123419-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:24.123764-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:12:24.124598-0500 | compress_modules | INFO - Quantizing model.layers.1.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:12:25.197086-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:12:25.198024-0500 | compress | METRIC - error 0.06\n",
      "2025-11-29T00:12:25.198703-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:25.199021-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:25.199327-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:25.199597-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:25.199878-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:25.200168-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:25.200450-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:25.200712-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:25.201025-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:12:25.201861-0500 | compress_modules | INFO - Quantizing model.layers.1.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:12:26.311340-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:12:26.312501-0500 | compress | METRIC - error 10.59\n",
      "2025-11-29T00:12:26.313323-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:26.313716-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:26.314002-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:26.314297-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:26.314569-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:26.314849-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:26.315165-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:26.315440-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:26.315750-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:12:26.316474-0500 | compress_modules | INFO - Quantizing model.layers.1.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:12:27.448695-0500 | compress | METRIC - time 1.13s\n",
      "2025-11-29T00:12:27.449850-0500 | compress | METRIC - error 9.35\n",
      "2025-11-29T00:12:27.450520-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:27.450862-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:27.451208-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:27.451494-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:27.451997-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:27.452258-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:27.452551-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:27.452829-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:27.453130-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:12:27.453727-0500 | compress_modules | INFO - Quantizing model.layers.1.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:12:30.406355-0500 | compress | METRIC - time 2.95s\n",
      "2025-11-29T00:12:30.408201-0500 | compress | METRIC - error 2.16\n",
      "2025-11-29T00:12:30.408865-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:30.409182-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:30.409469-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:30.409765-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:30.410077-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:30.410359-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:30.410635-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:12:30.410933-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:30.411264-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(2/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 191.83it/s]\n",
      "(3/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:12:43.169258-0500 | compress_modules | INFO - Quantizing model.layers.2.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:12:44.270029-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:12:44.271433-0500 | compress | METRIC - error 142.01\n",
      "2025-11-29T00:12:44.272380-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:44.272781-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:44.273136-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:44.273445-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:44.273770-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:44.274078-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:44.274692-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:44.275004-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:44.275561-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:12:44.276070-0500 | compress_modules | INFO - Quantizing model.layers.2.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:12:45.337765-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:12:45.338656-0500 | compress | METRIC - error 98.40\n",
      "2025-11-29T00:12:45.339459-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:45.339766-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:45.340057-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:45.340359-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:45.340650-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:45.340938-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:45.341235-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:45.341501-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:45.341801-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:12:45.342552-0500 | compress_modules | INFO - Quantizing model.layers.2.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:12:46.386591-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:12:46.387469-0500 | compress | METRIC - error 3.15\n",
      "2025-11-29T00:12:46.388348-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:46.388640-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:46.389080-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:46.389448-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:46.389720-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:46.389999-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:46.390289-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:46.390596-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:46.390890-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:12:46.391543-0500 | compress_modules | INFO - Quantizing model.layers.2.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:12:47.440565-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:12:47.441494-0500 | compress | METRIC - error 0.06\n",
      "2025-11-29T00:12:47.442334-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:47.442624-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:47.442942-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:47.443265-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:47.443793-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:47.444097-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:47.444410-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:47.444724-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:47.445041-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:12:47.445660-0500 | compress_modules | INFO - Quantizing model.layers.2.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:12:48.562332-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:12:48.563604-0500 | compress | METRIC - error 20.94\n",
      "2025-11-29T00:12:48.564412-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:48.564702-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:48.564983-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:48.565273-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:48.565571-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:48.565843-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:48.566126-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:48.566403-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:48.566715-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:12:48.567486-0500 | compress_modules | INFO - Quantizing model.layers.2.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:12:49.706988-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:12:49.708076-0500 | compress | METRIC - error 15.35\n",
      "2025-11-29T00:12:49.708790-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:49.709086-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:49.709389-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:49.709693-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:49.709966-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:49.710258-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:49.710516-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:12:49.710816-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:49.711136-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:12:49.711923-0500 | compress_modules | INFO - Quantizing model.layers.2.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:12:52.651072-0500 | compress | METRIC - time 2.94s\n",
      "2025-11-29T00:12:52.652632-0500 | compress | METRIC - error 0.36\n",
      "2025-11-29T00:12:52.653509-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:52.653965-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:12:52.654257-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:52.654571-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:52.654872-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:12:52.655177-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:52.655447-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:12:52.655731-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:12:52.656046-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(3/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 163.62it/s]\n",
      "(4/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 49.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:13:06.974584-0500 | compress_modules | INFO - Quantizing model.layers.3.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:13:08.064986-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:13:08.065932-0500 | compress | METRIC - error 83.60\n",
      "2025-11-29T00:13:08.066862-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:08.067319-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:08.067942-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:08.068349-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:08.068774-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:08.069168-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:08.069542-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:08.069937-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:08.070366-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:13:08.071442-0500 | compress_modules | INFO - Quantizing model.layers.3.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:13:09.135779-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:13:09.136617-0500 | compress | METRIC - error 45.53\n",
      "2025-11-29T00:13:09.137499-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:09.137808-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:09.138123-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:09.138415-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:09.138720-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:09.139014-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:09.139286-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:09.139575-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:09.139858-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:13:09.140608-0500 | compress_modules | INFO - Quantizing model.layers.3.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:13:10.178001-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:13:10.178859-0500 | compress | METRIC - error 3.92\n",
      "2025-11-29T00:13:10.179718-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:10.180096-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:10.180415-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:10.180710-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:10.180986-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:10.181293-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:10.181573-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:10.181848-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:10.182159-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:13:10.182899-0500 | compress_modules | INFO - Quantizing model.layers.3.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:13:11.262778-0500 | compress | METRIC - time 1.08s\n",
      "2025-11-29T00:13:11.263784-0500 | compress | METRIC - error 0.12\n",
      "2025-11-29T00:13:11.264838-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:11.265325-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:11.265649-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:11.265954-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:11.266280-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:11.266611-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:11.266912-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:11.267222-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:11.267559-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:13:11.268428-0500 | compress_modules | INFO - Quantizing model.layers.3.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:13:12.387572-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:13:12.388822-0500 | compress | METRIC - error 28.96\n",
      "2025-11-29T00:13:12.389656-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:12.390000-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:12.390330-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:12.390644-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:12.391015-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:12.391323-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:12.391630-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:12.391932-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:12.392275-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:13:12.393346-0500 | compress_modules | INFO - Quantizing model.layers.3.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:13:13.529707-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:13:13.531009-0500 | compress | METRIC - error 17.25\n",
      "2025-11-29T00:13:13.531908-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:13.532343-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:13.532769-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:13.533197-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:13.533610-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:13.534007-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:13.534428-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:13.534815-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:13.535248-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:13:13.536623-0500 | compress_modules | INFO - Quantizing model.layers.3.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:13:16.508633-0500 | compress | METRIC - time 2.97s\n",
      "2025-11-29T00:13:16.510451-0500 | compress | METRIC - error 0.51\n",
      "2025-11-29T00:13:16.511141-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:16.511469-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:16.511787-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:16.512068-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:16.512356-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:16.512633-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:16.512909-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:13:16.513224-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:16.513547-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(4/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 175.28it/s]\n",
      "(5/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:13:29.541526-0500 | compress_modules | INFO - Quantizing model.layers.4.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:13:30.639483-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:13:30.640582-0500 | compress | METRIC - error 96.33\n",
      "2025-11-29T00:13:30.641316-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:30.641682-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:30.641992-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:30.642287-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:30.642584-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:30.642868-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:30.643191-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:30.643480-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:30.643797-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:13:30.644583-0500 | compress_modules | INFO - Quantizing model.layers.4.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:13:31.683593-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:13:31.684559-0500 | compress | METRIC - error 51.15\n",
      "2025-11-29T00:13:31.685564-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:31.685913-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:31.686283-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:31.686653-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:31.687046-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:31.687399-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:31.687708-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:31.688006-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:31.688347-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:13:31.689211-0500 | compress_modules | INFO - Quantizing model.layers.4.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:13:32.727991-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:13:32.728844-0500 | compress | METRIC - error 3.51\n",
      "2025-11-29T00:13:32.729670-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:32.729990-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:32.730281-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:32.730576-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:32.730859-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:32.731161-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:32.731435-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:32.731700-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:32.731996-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:13:32.732745-0500 | compress_modules | INFO - Quantizing model.layers.4.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:13:33.795415-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:13:33.796421-0500 | compress | METRIC - error 0.22\n",
      "2025-11-29T00:13:33.797122-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:33.797431-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:33.797720-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:33.798016-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:33.798282-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:33.798580-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:33.799150-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:33.799417-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:33.799740-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:13:33.800276-0500 | compress_modules | INFO - Quantizing model.layers.4.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:13:34.917794-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:13:34.919023-0500 | compress | METRIC - error 39.88\n",
      "2025-11-29T00:13:34.919836-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:34.920192-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:34.920504-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:34.920797-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:34.921091-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:34.921374-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:34.921646-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:34.921959-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:34.922261-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:13:34.923048-0500 | compress_modules | INFO - Quantizing model.layers.4.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:13:36.058277-0500 | compress | METRIC - time 1.13s\n",
      "2025-11-29T00:13:36.059483-0500 | compress | METRIC - error 20.56\n",
      "2025-11-29T00:13:36.060414-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:36.060750-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:36.061080-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:36.061387-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:36.061697-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:36.062019-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:36.062343-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:36.062657-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:36.063532-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:13:36.064048-0500 | compress_modules | INFO - Quantizing model.layers.4.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:13:39.040536-0500 | compress | METRIC - time 2.98s\n",
      "2025-11-29T00:13:39.042028-0500 | compress | METRIC - error 0.71\n",
      "2025-11-29T00:13:39.042792-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:39.043093-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:39.043378-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:39.043840-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:39.044102-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:39.044383-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:39.044659-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:13:39.044943-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:39.045235-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(5/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 161.79it/s]\n",
      "(6/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:13:52.332068-0500 | compress_modules | INFO - Quantizing model.layers.5.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:13:53.443329-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:13:53.444528-0500 | compress | METRIC - error 121.75\n",
      "2025-11-29T00:13:53.445483-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:53.445831-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:53.446164-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:53.446538-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:53.446886-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:53.447281-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:53.447613-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:53.447916-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:53.448255-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:13:53.449151-0500 | compress_modules | INFO - Quantizing model.layers.5.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:13:54.537503-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:13:54.538600-0500 | compress | METRIC - error 80.67\n",
      "2025-11-29T00:13:54.539483-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:54.539814-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:54.540158-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:54.540481-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:54.540799-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:54.541128-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:54.541428-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:54.541760-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:54.542083-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:13:54.542980-0500 | compress_modules | INFO - Quantizing model.layers.5.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:13:55.608416-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:13:55.609393-0500 | compress | METRIC - error 3.84\n",
      "2025-11-29T00:13:55.610308-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:55.610677-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:55.611023-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:55.611378-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:55.611700-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:55.612021-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:55.612318-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:55.612623-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:55.612980-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:13:55.613883-0500 | compress_modules | INFO - Quantizing model.layers.5.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:13:56.703783-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:13:56.704882-0500 | compress | METRIC - error 0.20\n",
      "2025-11-29T00:13:56.705845-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:56.706195-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:56.706527-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:56.706862-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:56.707194-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:56.707517-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:56.707826-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:56.708125-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:56.708491-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:13:56.709441-0500 | compress_modules | INFO - Quantizing model.layers.5.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:13:57.836954-0500 | compress | METRIC - time 1.13s\n",
      "2025-11-29T00:13:57.838305-0500 | compress | METRIC - error 41.99\n",
      "2025-11-29T00:13:57.839064-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:57.839463-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:57.839758-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:57.840182-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:57.840529-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:57.840786-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:57.841074-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:57.841346-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:57.841662-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:13:57.842294-0500 | compress_modules | INFO - Quantizing model.layers.5.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:13:58.970507-0500 | compress | METRIC - time 1.13s\n",
      "2025-11-29T00:13:58.971933-0500 | compress | METRIC - error 21.95\n",
      "2025-11-29T00:13:58.972543-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:58.972834-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:13:58.973140-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:58.973447-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:58.973739-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:13:58.974310-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:58.974594-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:13:58.974871-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:13:58.975209-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:13:58.975803-0500 | compress_modules | INFO - Quantizing model.layers.5.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:14:01.983603-0500 | compress | METRIC - time 3.01s\n",
      "2025-11-29T00:14:01.985309-0500 | compress | METRIC - error 1.00\n",
      "2025-11-29T00:14:01.986215-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:01.986672-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:01.987037-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:01.987373-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:01.987695-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:01.988005-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:01.988308-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:14:01.988626-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:01.988963-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(6/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 180.07it/s]\n",
      "(7/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:14:14.982148-0500 | compress_modules | INFO - Quantizing model.layers.6.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:14:16.097706-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:14:16.098648-0500 | compress | METRIC - error 102.12\n",
      "2025-11-29T00:14:16.099360-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:16.099658-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:16.099980-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:16.100276-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:16.100559-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:16.100837-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:16.101138-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:16.101415-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:16.101720-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:14:16.102509-0500 | compress_modules | INFO - Quantizing model.layers.6.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:14:17.178780-0500 | compress | METRIC - time 1.08s\n",
      "2025-11-29T00:14:17.179728-0500 | compress | METRIC - error 60.84\n",
      "2025-11-29T00:14:17.180391-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:17.180708-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:17.181007-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:17.181309-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:17.181608-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:17.181891-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:17.182180-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:17.182442-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:17.182746-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:14:17.183526-0500 | compress_modules | INFO - Quantizing model.layers.6.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:14:18.237037-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:14:18.237975-0500 | compress | METRIC - error 3.04\n",
      "2025-11-29T00:14:18.238838-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:18.239199-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:18.239522-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:18.239967-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:18.240242-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:18.240536-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:18.240802-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:18.241085-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:18.241403-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:14:18.242106-0500 | compress_modules | INFO - Quantizing model.layers.6.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:14:19.317667-0500 | compress | METRIC - time 1.08s\n",
      "2025-11-29T00:14:19.318564-0500 | compress | METRIC - error 0.29\n",
      "2025-11-29T00:14:19.319253-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:19.319555-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:19.319852-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:19.320128-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:19.320403-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:19.320944-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:19.321206-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:19.321495-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:19.321792-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:14:19.322351-0500 | compress_modules | INFO - Quantizing model.layers.6.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:14:20.464601-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:14:20.465788-0500 | compress | METRIC - error 55.49\n",
      "2025-11-29T00:14:20.466453-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:20.466767-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:20.467099-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:20.467371-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:20.467652-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:20.467950-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:20.468223-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:20.468520-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:20.468822-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:14:20.469582-0500 | compress_modules | INFO - Quantizing model.layers.6.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:14:21.622152-0500 | compress | METRIC - time 1.15s\n",
      "2025-11-29T00:14:21.623427-0500 | compress | METRIC - error 23.44\n",
      "2025-11-29T00:14:21.624294-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:21.624690-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:21.625119-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:21.625561-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:21.625969-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:21.626357-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:21.626762-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:21.627165-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:21.627585-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:14:21.628810-0500 | compress_modules | INFO - Quantizing model.layers.6.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:14:24.839162-0500 | compress | METRIC - time 3.21s\n",
      "2025-11-29T00:14:24.840604-0500 | compress | METRIC - error 0.93\n",
      "2025-11-29T00:14:24.841317-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:24.841719-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:24.841995-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:24.842321-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:24.842600-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:24.842880-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:24.843177-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:14:24.843460-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:24.843759-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(7/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 160.73it/s]\n",
      "(8/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:14:38.138384-0500 | compress_modules | INFO - Quantizing model.layers.7.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:14:39.253536-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:14:39.254647-0500 | compress | METRIC - error 89.80\n",
      "2025-11-29T00:14:39.255406-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:39.255765-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:39.256076-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:39.256553-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:39.256829-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:39.257142-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:39.257425-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:39.257730-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:39.258078-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:14:39.258726-0500 | compress_modules | INFO - Quantizing model.layers.7.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:14:40.315293-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:14:40.316848-0500 | compress | METRIC - error 46.32\n",
      "2025-11-29T00:14:40.317564-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:40.317879-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:40.318171-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:40.318467-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:40.318743-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:40.319296-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:40.319572-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:40.319863-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:40.320173-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:14:40.320747-0500 | compress_modules | INFO - Quantizing model.layers.7.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:14:41.376232-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:14:41.377367-0500 | compress | METRIC - error 3.38\n",
      "2025-11-29T00:14:41.378207-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:41.378505-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:41.378815-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:41.379121-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:41.379421-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:41.379703-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:41.379991-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:41.380277-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:41.380589-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:14:41.381359-0500 | compress_modules | INFO - Quantizing model.layers.7.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:14:42.499835-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:14:42.500862-0500 | compress | METRIC - error 0.41\n",
      "2025-11-29T00:14:42.501476-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:42.501771-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:42.502101-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:42.502394-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:42.502671-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:42.502956-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:42.503247-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:42.503511-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:42.503824-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:14:42.504589-0500 | compress_modules | INFO - Quantizing model.layers.7.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:14:43.706066-0500 | compress | METRIC - time 1.20s\n",
      "2025-11-29T00:14:43.707323-0500 | compress | METRIC - error 51.45\n",
      "2025-11-29T00:14:43.708150-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:43.708572-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:43.708851-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:43.709158-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:43.709448-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:43.709720-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:43.710013-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:43.710288-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:43.710582-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:14:43.711348-0500 | compress_modules | INFO - Quantizing model.layers.7.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:14:44.850921-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:14:44.852065-0500 | compress | METRIC - error 25.77\n",
      "2025-11-29T00:14:44.853083-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:44.853406-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:44.853758-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:44.854078-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:44.854397-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:44.854708-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:44.855052-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:14:44.855781-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:44.856220-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:14:44.856946-0500 | compress_modules | INFO - Quantizing model.layers.7.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:14:47.858976-0500 | compress | METRIC - time 3.00s\n",
      "2025-11-29T00:14:47.860528-0500 | compress | METRIC - error 1.05\n",
      "2025-11-29T00:14:47.861350-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:47.861646-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:14:47.861977-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:47.862250-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:47.862536-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:14:47.862817-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:47.863110-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:14:47.863399-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:14:47.863697-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(8/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.16it/s]\n",
      "(9/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:15:01.034581-0500 | compress_modules | INFO - Quantizing model.layers.8.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:15:02.137896-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:15:02.139100-0500 | compress | METRIC - error 123.70\n",
      "2025-11-29T00:15:02.140044-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:02.140440-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:02.140779-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:02.141113-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:02.141447-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:02.141749-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:02.142073-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:02.142376-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:02.142701-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:15:02.143571-0500 | compress_modules | INFO - Quantizing model.layers.8.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:15:03.217032-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:15:03.217949-0500 | compress | METRIC - error 88.24\n",
      "2025-11-29T00:15:03.218615-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:03.218921-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:03.219219-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:03.219507-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:03.219795-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:03.220074-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:03.220370-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:03.220642-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:03.220939-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:15:03.221679-0500 | compress_modules | INFO - Quantizing model.layers.8.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:15:04.262451-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:15:04.263349-0500 | compress | METRIC - error 3.59\n",
      "2025-11-29T00:15:04.264165-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:04.264561-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:04.264838-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:04.265119-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:04.265429-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:04.265724-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:04.265991-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:04.266279-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:04.266574-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:15:04.267298-0500 | compress_modules | INFO - Quantizing model.layers.8.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:15:05.337750-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:15:05.338649-0500 | compress | METRIC - error 0.51\n",
      "2025-11-29T00:15:05.339574-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:05.339883-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:05.340183-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:05.340467-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:05.340776-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:05.341053-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:05.341327-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:05.341610-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:05.341924-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:15:05.342666-0500 | compress_modules | INFO - Quantizing model.layers.8.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:15:06.458553-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:15:06.459779-0500 | compress | METRIC - error 57.57\n",
      "2025-11-29T00:15:06.460643-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:06.460946-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:06.461251-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:06.461555-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:06.461826-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:06.462110-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:06.462388-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:06.462683-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:06.463010-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:15:06.463798-0500 | compress_modules | INFO - Quantizing model.layers.8.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:15:07.598198-0500 | compress | METRIC - time 1.13s\n",
      "2025-11-29T00:15:07.599286-0500 | compress | METRIC - error 26.54\n",
      "2025-11-29T00:15:07.600253-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:07.600570-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:07.600865-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:07.601174-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:07.601446-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:07.601733-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:07.602027-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:07.602305-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:07.602614-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:15:07.603377-0500 | compress_modules | INFO - Quantizing model.layers.8.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:15:10.579365-0500 | compress | METRIC - time 2.98s\n",
      "2025-11-29T00:15:10.580839-0500 | compress | METRIC - error 1.18\n",
      "2025-11-29T00:15:10.581553-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:10.581855-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:10.582152-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:10.582619-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:10.582898-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:10.583207-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:10.583477-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:15:10.583773-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:10.584097-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(9/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.25it/s]\n",
      "(10/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:15:23.709271-0500 | compress_modules | INFO - Quantizing model.layers.9.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:15:24.803912-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:15:24.804879-0500 | compress | METRIC - error 124.79\n",
      "2025-11-29T00:15:24.805705-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:24.806033-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:24.806332-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:24.806626-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:24.806899-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:24.807203-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:24.807492-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:24.807760-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:24.808107-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:15:24.808870-0500 | compress_modules | INFO - Quantizing model.layers.9.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:15:25.853834-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:15:25.855016-0500 | compress | METRIC - error 98.81\n",
      "2025-11-29T00:15:25.855707-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:25.856068-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:25.856386-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:25.856665-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:25.856949-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:25.857252-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:25.857552-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:25.857858-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:25.858185-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:15:25.858964-0500 | compress_modules | INFO - Quantizing model.layers.9.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:15:26.904241-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:15:26.905137-0500 | compress | METRIC - error 3.66\n",
      "2025-11-29T00:15:26.905973-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:26.906266-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:26.906580-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:26.906849-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:26.907148-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:26.907414-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:26.907714-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:26.907999-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:26.908297-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:15:26.909044-0500 | compress_modules | INFO - Quantizing model.layers.9.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:15:27.976894-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:15:27.978084-0500 | compress | METRIC - error 0.66\n",
      "2025-11-29T00:15:27.978689-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:27.979013-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:27.979302-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:27.979650-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:27.979976-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:27.980296-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:27.980616-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:27.980903-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:27.981230-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:15:27.981990-0500 | compress_modules | INFO - Quantizing model.layers.9.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:15:29.098721-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:15:29.099971-0500 | compress | METRIC - error 55.07\n",
      "2025-11-29T00:15:29.100635-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:29.100923-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:29.101212-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:29.101686-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:29.101965-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:29.102246-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:29.102530-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:29.102806-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:29.103138-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:15:29.103800-0500 | compress_modules | INFO - Quantizing model.layers.9.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:15:30.225525-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:15:30.226596-0500 | compress | METRIC - error 27.01\n",
      "2025-11-29T00:15:30.243786-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:30.244302-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:30.244755-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:30.245062-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:30.245384-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:30.245831-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:30.246196-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:30.246465-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:30.246778-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:15:30.247346-0500 | compress_modules | INFO - Quantizing model.layers.9.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:15:33.222540-0500 | compress | METRIC - time 2.97s\n",
      "2025-11-29T00:15:33.224205-0500 | compress | METRIC - error 1.03\n",
      "2025-11-29T00:15:33.225081-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:33.225369-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:33.225675-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:33.225953-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:33.226240-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:33.226533-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:33.226814-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:15:33.227101-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:33.227427-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(10/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 177.75it/s]\n",
      "(11/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:15:46.222336-0500 | compress_modules | INFO - Quantizing model.layers.10.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:15:47.294430-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:15:47.295386-0500 | compress | METRIC - error 101.13\n",
      "2025-11-29T00:15:47.296373-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:47.296669-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:47.296980-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:47.297256-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:47.297547-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:47.297829-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:47.298104-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:47.298397-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:47.298695-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:15:47.299473-0500 | compress_modules | INFO - Quantizing model.layers.10.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:15:48.369215-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:15:48.370121-0500 | compress | METRIC - error 84.61\n",
      "2025-11-29T00:15:48.371003-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:48.371308-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:48.371610-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:48.371881-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:48.372206-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:48.372492-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:48.372789-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:48.373071-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:48.373377-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:15:48.374132-0500 | compress_modules | INFO - Quantizing model.layers.10.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:15:49.420178-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:15:49.421191-0500 | compress | METRIC - error 3.73\n",
      "2025-11-29T00:15:49.422179-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:49.422506-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:49.422837-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:49.423192-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:49.423495-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:49.423834-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:49.424138-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:49.424446-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:49.424780-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:15:49.425641-0500 | compress_modules | INFO - Quantizing model.layers.10.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:15:50.488415-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:15:50.489297-0500 | compress | METRIC - error 0.50\n",
      "2025-11-29T00:15:50.489987-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:50.490309-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:50.490606-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:50.490886-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:50.491186-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:50.491715-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:50.491981-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:50.492261-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:50.492568-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:15:50.493110-0500 | compress_modules | INFO - Quantizing model.layers.10.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:15:51.614921-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:15:51.616144-0500 | compress | METRIC - error 50.49\n",
      "2025-11-29T00:15:51.616827-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:51.617117-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:51.617428-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:51.617708-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:51.617977-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:51.618267-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:51.618552-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:51.618830-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:51.619157-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:15:51.619927-0500 | compress_modules | INFO - Quantizing model.layers.10.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:15:52.756680-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:15:52.757918-0500 | compress | METRIC - error 29.31\n",
      "2025-11-29T00:15:52.758778-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:52.759246-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:52.759691-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:52.760056-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:52.760402-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:52.760743-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:52.761096-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:15:52.761500-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:52.761892-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:15:52.763049-0500 | compress_modules | INFO - Quantizing model.layers.10.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:15:55.747328-0500 | compress | METRIC - time 2.98s\n",
      "2025-11-29T00:15:55.748938-0500 | compress | METRIC - error 1.23\n",
      "2025-11-29T00:15:55.749750-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:55.750059-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:15:55.750484-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:55.750757-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:55.751072-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:15:55.751363-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:55.751651-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:15:55.751923-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:15:55.752242-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(11/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 162.44it/s]\n",
      "(12/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:16:09.017107-0500 | compress_modules | INFO - Quantizing model.layers.11.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:16:10.119623-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:16:10.120531-0500 | compress | METRIC - error 82.65\n",
      "2025-11-29T00:16:10.121534-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:10.121833-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:10.122278-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:10.122636-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:10.122917-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:10.123211-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:10.123501-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:10.123761-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:10.124069-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:16:10.124722-0500 | compress_modules | INFO - Quantizing model.layers.11.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:16:11.175557-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:16:11.176451-0500 | compress | METRIC - error 61.09\n",
      "2025-11-29T00:16:11.177140-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:11.177438-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:11.177772-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:11.178078-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:11.178364-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:11.178659-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:11.178972-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:11.179266-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:11.179575-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:16:11.180319-0500 | compress_modules | INFO - Quantizing model.layers.11.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:16:12.280035-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:16:12.280951-0500 | compress | METRIC - error 4.03\n",
      "2025-11-29T00:16:12.281833-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:12.282248-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:12.282586-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:12.282900-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:12.283262-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:12.283586-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:12.283899-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:12.284207-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:12.284533-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:16:12.285399-0500 | compress_modules | INFO - Quantizing model.layers.11.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:16:13.354455-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:16:13.355481-0500 | compress | METRIC - error 0.57\n",
      "2025-11-29T00:16:13.356101-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:13.356391-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:13.356698-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:13.356972-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:13.357239-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:13.357527-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:13.357802-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:13.358072-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:13.358383-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:16:13.359130-0500 | compress_modules | INFO - Quantizing model.layers.11.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:16:14.481889-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:16:14.483219-0500 | compress | METRIC - error 54.70\n",
      "2025-11-29T00:16:14.483895-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:14.484254-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:14.484579-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:14.484870-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:14.485158-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:14.485491-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:14.485816-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:14.486142-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:14.486440-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:16:14.487501-0500 | compress_modules | INFO - Quantizing model.layers.11.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:16:15.613856-0500 | compress | METRIC - time 1.13s\n",
      "2025-11-29T00:16:15.615093-0500 | compress | METRIC - error 33.03\n",
      "2025-11-29T00:16:15.615902-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:15.616202-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:15.616515-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:15.616802-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:15.617088-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:15.617373-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:15.617650-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:15.618239-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:15.618545-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:16:15.619056-0500 | compress_modules | INFO - Quantizing model.layers.11.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:16:18.590952-0500 | compress | METRIC - time 2.97s\n",
      "2025-11-29T00:16:18.592731-0500 | compress | METRIC - error 1.46\n",
      "2025-11-29T00:16:18.593716-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:18.594052-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:18.594397-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:18.594724-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:18.595066-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:18.595390-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:18.595724-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:16:18.596028-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:18.596355-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(12/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 183.53it/s]\n",
      "(13/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:16:31.496012-0500 | compress_modules | INFO - Quantizing model.layers.12.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:16:32.597957-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:16:32.598997-0500 | compress | METRIC - error 134.98\n",
      "2025-11-29T00:16:32.599987-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:32.600308-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:32.600602-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:32.600890-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:32.601170-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:32.601442-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:32.601749-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:32.602039-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:32.602353-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:16:32.603145-0500 | compress_modules | INFO - Quantizing model.layers.12.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:16:33.644243-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:16:33.645370-0500 | compress | METRIC - error 164.35\n",
      "2025-11-29T00:16:33.645950-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:33.646236-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:33.646543-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:33.646829-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:33.647140-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:33.647408-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:33.647696-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:33.648001-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:33.648306-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:16:33.649072-0500 | compress_modules | INFO - Quantizing model.layers.12.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:16:34.687970-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:16:34.688890-0500 | compress | METRIC - error 5.30\n",
      "2025-11-29T00:16:34.689807-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:34.690213-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:34.690522-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:34.690804-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:34.691095-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:34.691372-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:34.691678-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:34.691944-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:34.692254-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:16:34.692999-0500 | compress_modules | INFO - Quantizing model.layers.12.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:16:35.759105-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:16:35.760044-0500 | compress | METRIC - error 0.68\n",
      "2025-11-29T00:16:35.760837-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:35.761130-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:35.761435-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:35.761734-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:35.762036-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:35.762308-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:35.762619-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:35.762911-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:35.763224-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:16:35.763991-0500 | compress_modules | INFO - Quantizing model.layers.12.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:16:36.879043-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:16:36.880289-0500 | compress | METRIC - error 58.95\n",
      "2025-11-29T00:16:36.880990-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:36.881347-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:36.881673-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:36.881959-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:36.882249-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:36.882548-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:36.882835-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:36.883124-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:36.883445-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:16:36.884343-0500 | compress_modules | INFO - Quantizing model.layers.12.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:16:38.024418-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:16:38.025668-0500 | compress | METRIC - error 33.82\n",
      "2025-11-29T00:16:38.026489-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:38.026790-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:38.027104-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:38.027400-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:38.027684-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:38.027966-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:38.028265-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:38.028533-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:38.028830-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:16:38.029593-0500 | compress_modules | INFO - Quantizing model.layers.12.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:16:40.994166-0500 | compress | METRIC - time 2.96s\n",
      "2025-11-29T00:16:40.995705-0500 | compress | METRIC - error 1.61\n",
      "2025-11-29T00:16:40.996590-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:40.996882-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:40.997194-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:40.997658-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:40.998050-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:40.998311-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:40.998609-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:16:40.998886-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:40.999214-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(13/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 181.55it/s]\n",
      "(14/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:16:53.933721-0500 | compress_modules | INFO - Quantizing model.layers.13.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:16:55.037770-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:16:55.038766-0500 | compress | METRIC - error 132.56\n",
      "2025-11-29T00:16:55.039852-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:55.040197-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:55.040591-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:55.040954-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:55.041303-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:55.041650-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:55.041960-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:55.042255-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:55.042604-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:16:55.043621-0500 | compress_modules | INFO - Quantizing model.layers.13.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:16:56.102774-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:16:56.103694-0500 | compress | METRIC - error 173.29\n",
      "2025-11-29T00:16:56.104353-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:56.104659-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:56.104959-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:56.105236-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:56.105520-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:56.105797-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:56.106077-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:56.106680-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:56.106995-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:16:56.107496-0500 | compress_modules | INFO - Quantizing model.layers.13.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:16:57.156729-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:16:57.157738-0500 | compress | METRIC - error 6.79\n",
      "2025-11-29T00:16:57.158721-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:57.159075-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:57.159401-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:57.159717-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:57.160029-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:57.160346-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:57.160639-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:57.160957-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:57.161274-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:16:57.162156-0500 | compress_modules | INFO - Quantizing model.layers.13.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:16:58.227569-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:16:58.228534-0500 | compress | METRIC - error 1.05\n",
      "2025-11-29T00:16:58.229214-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:58.229517-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:58.229840-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:58.230140-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:58.230411-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:58.230705-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:58.231015-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:58.231306-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:58.231603-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:16:58.232338-0500 | compress_modules | INFO - Quantizing model.layers.13.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:16:59.349895-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:16:59.351108-0500 | compress | METRIC - error 71.15\n",
      "2025-11-29T00:16:59.352053-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:59.352399-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:16:59.352724-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:59.353043-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:59.353394-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:16:59.353704-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:59.354015-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:16:59.354305-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:16:59.354637-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:16:59.355546-0500 | compress_modules | INFO - Quantizing model.layers.13.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:17:00.499167-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:17:00.500540-0500 | compress | METRIC - error 36.61\n",
      "2025-11-29T00:17:00.501514-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:00.502011-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:00.502563-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:00.503120-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:00.503665-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:00.504156-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:00.504639-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:00.505137-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:00.505611-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:17:00.507031-0500 | compress_modules | INFO - Quantizing model.layers.13.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:17:03.491859-0500 | compress | METRIC - time 2.98s\n",
      "2025-11-29T00:17:03.493434-0500 | compress | METRIC - error 2.09\n",
      "2025-11-29T00:17:03.494415-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:03.494889-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:03.495229-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:03.495584-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:03.495884-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:03.496195-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:03.496509-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:17:03.496805-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:03.497147-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(14/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 171.29it/s]\n",
      "(15/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:17:16.604455-0500 | compress_modules | INFO - Quantizing model.layers.14.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:17:17.683238-0500 | compress | METRIC - time 1.08s\n",
      "2025-11-29T00:17:17.684150-0500 | compress | METRIC - error 186.36\n",
      "2025-11-29T00:17:17.685199-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:17.685531-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:17.685841-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:17.686146-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:17.686416-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:17.686713-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:17.686999-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:17.687290-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:17.687603-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:17:17.688387-0500 | compress_modules | INFO - Quantizing model.layers.14.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:17:18.734656-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:17:18.735549-0500 | compress | METRIC - error 156.39\n",
      "2025-11-29T00:17:18.736499-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:18.736802-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:18.737104-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:18.737373-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:18.737646-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:18.737913-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:18.738201-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:18.738486-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:18.738786-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:17:18.739564-0500 | compress_modules | INFO - Quantizing model.layers.14.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:17:19.790475-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:17:19.791576-0500 | compress | METRIC - error 8.04\n",
      "2025-11-29T00:17:19.792161-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:19.792458-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:19.792757-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:19.793041-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:19.793530-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:19.793803-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:19.794086-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:19.794365-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:19.794663-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:17:19.795247-0500 | compress_modules | INFO - Quantizing model.layers.14.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:17:20.895273-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:17:20.896194-0500 | compress | METRIC - error 1.08\n",
      "2025-11-29T00:17:20.897057-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:20.897349-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:20.897653-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:20.897959-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:20.898234-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:20.898513-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:20.898804-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:20.899100-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:20.899415-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:17:20.900170-0500 | compress_modules | INFO - Quantizing model.layers.14.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:17:22.019132-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:17:22.020354-0500 | compress | METRIC - error 87.24\n",
      "2025-11-29T00:17:22.021149-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:22.021449-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:22.021763-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:22.022028-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:22.022522-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:22.022793-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:22.023074-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:22.023367-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:22.023659-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:17:22.024254-0500 | compress_modules | INFO - Quantizing model.layers.14.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:17:23.145513-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:17:23.146770-0500 | compress | METRIC - error 37.95\n",
      "2025-11-29T00:17:23.147453-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:23.147765-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:23.148069-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:23.148357-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:23.148650-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:23.148922-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:23.149213-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:23.149478-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:23.149791-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:17:23.150540-0500 | compress_modules | INFO - Quantizing model.layers.14.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:17:26.124436-0500 | compress | METRIC - time 2.97s\n",
      "2025-11-29T00:17:26.126065-0500 | compress | METRIC - error 2.59\n",
      "2025-11-29T00:17:26.126652-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:26.126976-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:26.127292-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:26.127578-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:26.127840-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:26.128123-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:26.128385-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:17:26.128658-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:26.128964-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(15/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 181.21it/s]\n",
      "(16/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:17:39.048965-0500 | compress_modules | INFO - Quantizing model.layers.15.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:17:40.158285-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:17:40.159220-0500 | compress | METRIC - error 178.18\n",
      "2025-11-29T00:17:40.160223-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:40.160547-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:40.160860-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:40.161146-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:40.161633-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:40.161916-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:40.162209-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:40.162492-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:40.162814-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:17:40.163463-0500 | compress_modules | INFO - Quantizing model.layers.15.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:17:41.220171-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:17:41.221070-0500 | compress | METRIC - error 193.26\n",
      "2025-11-29T00:17:41.222012-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:41.222324-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:41.222635-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:41.222921-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:41.223215-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:41.223515-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:41.223808-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:41.224093-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:41.224395-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:17:41.225166-0500 | compress_modules | INFO - Quantizing model.layers.15.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:17:42.278144-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:17:42.279084-0500 | compress | METRIC - error 6.29\n",
      "2025-11-29T00:17:42.279971-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:42.280277-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:42.280587-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:42.280889-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:42.281160-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:42.281449-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:42.281719-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:42.282009-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:42.282314-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:17:42.283066-0500 | compress_modules | INFO - Quantizing model.layers.15.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:17:43.436129-0500 | compress | METRIC - time 1.15s\n",
      "2025-11-29T00:17:43.436907-0500 | compress | METRIC - error 0.73\n",
      "2025-11-29T00:17:43.437824-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:43.438149-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:43.438443-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:43.438737-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:43.439037-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:43.439340-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:43.439616-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:43.439883-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:43.440199-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:17:43.440957-0500 | compress_modules | INFO - Quantizing model.layers.15.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:17:44.556093-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:17:44.557952-0500 | compress | METRIC - error 91.10\n",
      "2025-11-29T00:17:44.558632-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:44.558949-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:44.559280-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:44.559564-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:44.559869-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:44.560145-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:44.560416-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:44.560710-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:44.561011-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:17:44.561804-0500 | compress_modules | INFO - Quantizing model.layers.15.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:17:45.680403-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:17:45.681815-0500 | compress | METRIC - error 38.25\n",
      "2025-11-29T00:17:45.682980-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:45.683332-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:45.683666-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:45.684169-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:45.684477-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:45.684799-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:45.685134-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:17:45.685433-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:45.685797-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:17:45.686587-0500 | compress_modules | INFO - Quantizing model.layers.15.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:17:48.666083-0500 | compress | METRIC - time 2.98s\n",
      "2025-11-29T00:17:48.667863-0500 | compress | METRIC - error 2.90\n",
      "2025-11-29T00:17:48.668558-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:48.668864-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:17:48.669163-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:48.669456-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:48.669728-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:17:48.670026-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:48.670312-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:17:48.670578-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:17:48.670915-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(16/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 184.00it/s]\n",
      "(17/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:18:01.568355-0500 | compress_modules | INFO - Quantizing model.layers.16.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:18:02.651286-0500 | compress | METRIC - time 1.08s\n",
      "2025-11-29T00:18:02.652223-0500 | compress | METRIC - error 182.26\n",
      "2025-11-29T00:18:02.653230-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:02.653544-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:02.653854-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:02.654143-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:02.654427-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:02.654706-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:02.654987-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:02.655264-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:02.655552-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:18:02.656296-0500 | compress_modules | INFO - Quantizing model.layers.16.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:18:03.731376-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:18:03.732451-0500 | compress | METRIC - error 190.62\n",
      "2025-11-29T00:18:03.733210-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:03.733561-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:03.733880-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:03.734169-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:03.734465-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:03.734759-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:03.735059-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:03.735343-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:03.735635-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:18:03.736383-0500 | compress_modules | INFO - Quantizing model.layers.16.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:18:04.782253-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:18:04.783166-0500 | compress | METRIC - error 11.93\n",
      "2025-11-29T00:18:04.784049-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:04.784345-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:04.784778-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:04.785069-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:04.785410-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:04.785724-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:04.786053-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:04.786331-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:04.786644-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:18:04.787337-0500 | compress_modules | INFO - Quantizing model.layers.16.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:18:05.859681-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:18:05.860662-0500 | compress | METRIC - error 0.54\n",
      "2025-11-29T00:18:05.861455-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:05.861758-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:05.862195-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:05.862537-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:05.862806-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:05.863175-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:05.863487-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:05.863784-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:05.864372-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:18:05.864807-0500 | compress_modules | INFO - Quantizing model.layers.16.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:18:07.005675-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:18:07.006887-0500 | compress | METRIC - error 81.74\n",
      "2025-11-29T00:18:07.007598-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:07.007898-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:07.008194-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:07.008483-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:07.008759-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:07.009031-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:07.009330-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:07.009599-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:07.009904-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:18:07.010670-0500 | compress_modules | INFO - Quantizing model.layers.16.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:18:08.128585-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:18:08.129777-0500 | compress | METRIC - error 37.62\n",
      "2025-11-29T00:18:08.130637-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:08.130976-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:08.131334-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:08.131655-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:08.131952-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:08.132270-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:08.132566-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:08.132838-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:08.133147-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:18:08.133895-0500 | compress_modules | INFO - Quantizing model.layers.16.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:18:11.102386-0500 | compress | METRIC - time 2.97s\n",
      "2025-11-29T00:18:11.103984-0500 | compress | METRIC - error 2.44\n",
      "2025-11-29T00:18:11.104704-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:11.105008-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:11.105296-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:11.105579-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:11.106077-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:11.106344-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:11.106630-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:18:11.106933-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:11.107239-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(17/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 173.29it/s]\n",
      "(18/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:18:24.186087-0500 | compress_modules | INFO - Quantizing model.layers.17.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:18:25.263990-0500 | compress | METRIC - time 1.08s\n",
      "2025-11-29T00:18:25.264938-0500 | compress | METRIC - error 169.26\n",
      "2025-11-29T00:18:25.265658-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:25.265964-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:25.266274-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:25.266565-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:25.266839-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:25.267150-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:25.267423-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:25.267697-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:25.268010-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:18:25.268769-0500 | compress_modules | INFO - Quantizing model.layers.17.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:18:26.317591-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:18:26.318648-0500 | compress | METRIC - error 148.58\n",
      "2025-11-29T00:18:26.319370-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:26.319671-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:26.319972-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:26.320280-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:26.320582-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:26.320911-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:26.321207-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:26.321483-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:26.322121-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:18:26.322555-0500 | compress_modules | INFO - Quantizing model.layers.17.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:18:27.374502-0500 | compress | METRIC - time 1.05s\n",
      "2025-11-29T00:18:27.375467-0500 | compress | METRIC - error 12.25\n",
      "2025-11-29T00:18:27.376388-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:27.376695-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:27.377004-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:27.377315-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:27.377611-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:27.377898-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:27.378187-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:27.378463-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:27.378753-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:18:27.379506-0500 | compress_modules | INFO - Quantizing model.layers.17.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:18:28.503939-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:18:28.504739-0500 | compress | METRIC - error 0.49\n",
      "2025-11-29T00:18:28.505439-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:28.505732-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:28.506039-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:28.506331-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:28.506639-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:28.506941-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:28.507223-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:28.507490-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:28.507805-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:18:28.508550-0500 | compress_modules | INFO - Quantizing model.layers.17.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:18:29.641365-0500 | compress | METRIC - time 1.13s\n",
      "2025-11-29T00:18:29.642642-0500 | compress | METRIC - error 86.49\n",
      "2025-11-29T00:18:29.643480-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:29.643835-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:29.644149-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:29.644448-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:29.644935-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:29.645214-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:29.645506-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:29.645778-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:29.646083-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:18:29.646686-0500 | compress_modules | INFO - Quantizing model.layers.17.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:18:30.757739-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:18:30.758795-0500 | compress | METRIC - error 38.64\n",
      "2025-11-29T00:18:30.759641-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:30.759934-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:30.760219-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:30.760516-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:30.760800-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:30.761079-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:30.761365-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:30.761639-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:30.761937-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:18:30.762688-0500 | compress_modules | INFO - Quantizing model.layers.17.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:18:33.710856-0500 | compress | METRIC - time 2.95s\n",
      "2025-11-29T00:18:33.712423-0500 | compress | METRIC - error 2.75\n",
      "2025-11-29T00:18:33.713053-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:33.713383-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:33.713653-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:33.713944-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:33.714212-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:33.714503-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:33.714770-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:18:33.715094-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:33.715392-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(18/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 175.48it/s]\n",
      "(19/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:18:46.717014-0500 | compress_modules | INFO - Quantizing model.layers.18.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:18:47.808826-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:18:47.809862-0500 | compress | METRIC - error 200.86\n",
      "2025-11-29T00:18:47.810741-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:47.811053-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:47.811358-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:47.811622-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:47.811921-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:47.812203-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:47.812503-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:47.812779-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:47.813115-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:18:47.814029-0500 | compress_modules | INFO - Quantizing model.layers.18.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:18:48.873718-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:18:48.874653-0500 | compress | METRIC - error 190.54\n",
      "2025-11-29T00:18:48.875521-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:48.875831-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:48.876119-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:48.876428-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:48.876712-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:48.877001-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:48.877275-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:48.877545-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:48.877876-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:18:48.878610-0500 | compress_modules | INFO - Quantizing model.layers.18.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:18:49.916514-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:18:49.917472-0500 | compress | METRIC - error 12.88\n",
      "2025-11-29T00:18:49.918533-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:49.919064-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:49.919459-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:49.919774-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:49.920108-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:49.920427-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:49.920727-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:49.921038-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:49.921387-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:18:49.922256-0500 | compress_modules | INFO - Quantizing model.layers.18.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:18:50.989632-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:18:50.991133-0500 | compress | METRIC - error 0.55\n",
      "2025-11-29T00:18:50.992069-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:50.992381-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:50.992681-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:50.992990-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:50.993268-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:50.993546-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:50.993854-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:50.994131-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:50.994448-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:18:50.995217-0500 | compress_modules | INFO - Quantizing model.layers.18.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:18:52.111516-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:18:52.112753-0500 | compress | METRIC - error 91.84\n",
      "2025-11-29T00:18:52.113590-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:52.113883-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:52.114190-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:52.114477-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:52.114742-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:52.115046-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:52.115324-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:52.115614-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:52.115970-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:18:52.116816-0500 | compress_modules | INFO - Quantizing model.layers.18.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:18:53.239760-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:18:53.241316-0500 | compress | METRIC - error 41.51\n",
      "2025-11-29T00:18:53.241984-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:53.242349-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:53.242664-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:53.242965-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:53.243251-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:53.243549-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:53.243833-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:18:53.244124-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:53.244428-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:18:53.245303-0500 | compress_modules | INFO - Quantizing model.layers.18.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:18:56.301117-0500 | compress | METRIC - time 3.06s\n",
      "2025-11-29T00:18:56.304485-0500 | compress | METRIC - error 2.85\n",
      "2025-11-29T00:18:56.305517-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:56.305940-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:18:56.306557-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:56.306946-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:56.307515-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:18:56.307914-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:56.308270-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:18:56.308635-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:18:56.309085-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(19/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 121.24it/s]\n",
      "(20/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:19:10.806360-0500 | compress_modules | INFO - Quantizing model.layers.19.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:19:11.916353-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:19:11.917623-0500 | compress | METRIC - error 191.11\n",
      "2025-11-29T00:19:11.918671-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:11.919089-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:11.919460-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:11.919815-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:11.920152-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:11.920484-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:11.920803-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:11.921120-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:11.921465-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:19:11.922369-0500 | compress_modules | INFO - Quantizing model.layers.19.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:19:13.037962-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:19:13.039541-0500 | compress | METRIC - error 173.39\n",
      "2025-11-29T00:19:13.040513-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:13.040837-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:13.041143-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:13.041435-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:13.041731-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:13.042020-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:13.042602-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:13.042877-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:13.043261-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:19:13.043854-0500 | compress_modules | INFO - Quantizing model.layers.19.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:19:14.124213-0500 | compress | METRIC - time 1.08s\n",
      "2025-11-29T00:19:14.125235-0500 | compress | METRIC - error 14.80\n",
      "2025-11-29T00:19:14.125956-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:14.126267-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:14.126565-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:14.126860-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:14.127176-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:14.127462-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:14.127745-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:14.128028-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:14.128332-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:19:14.129114-0500 | compress_modules | INFO - Quantizing model.layers.19.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:19:15.286322-0500 | compress | METRIC - time 1.16s\n",
      "2025-11-29T00:19:15.287340-0500 | compress | METRIC - error 0.81\n",
      "2025-11-29T00:19:15.288059-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:15.288371-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:15.288686-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:15.288971-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:15.289279-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:15.289560-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:15.289847-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:15.290128-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:15.290426-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:19:15.291216-0500 | compress_modules | INFO - Quantizing model.layers.19.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:19:16.469897-0500 | compress | METRIC - time 1.18s\n",
      "2025-11-29T00:19:16.471032-0500 | compress | METRIC - error 101.17\n",
      "2025-11-29T00:19:16.471962-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:16.472321-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:16.472676-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:16.472965-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:16.473277-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:16.473573-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:16.473856-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:16.474148-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:16.474451-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:19:16.475243-0500 | compress_modules | INFO - Quantizing model.layers.19.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:19:17.674805-0500 | compress | METRIC - time 1.20s\n",
      "2025-11-29T00:19:17.675950-0500 | compress | METRIC - error 45.29\n",
      "2025-11-29T00:19:17.676672-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:17.676975-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:17.677274-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:17.677551-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:17.677823-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:17.678098-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:17.678388-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:17.678653-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:17.679328-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:19:17.679792-0500 | compress_modules | INFO - Quantizing model.layers.19.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:19:20.651594-0500 | compress | METRIC - time 2.97s\n",
      "2025-11-29T00:19:20.653354-0500 | compress | METRIC - error 3.53\n",
      "2025-11-29T00:19:20.654074-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:20.654384-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:20.654722-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:20.655037-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:20.655323-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:20.655630-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:20.655918-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:19:20.656200-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:20.656492-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(20/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 154.19it/s]\n",
      "(21/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:19:34.163165-0500 | compress_modules | INFO - Quantizing model.layers.20.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:19:35.261528-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:19:35.262654-0500 | compress | METRIC - error 205.27\n",
      "2025-11-29T00:19:35.263309-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:35.263617-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:35.263938-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:35.264216-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:35.264514-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:35.264786-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:35.265072-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:35.265337-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:35.265642-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:19:35.266401-0500 | compress_modules | INFO - Quantizing model.layers.20.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:19:36.335670-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:19:36.336798-0500 | compress | METRIC - error 188.06\n",
      "2025-11-29T00:19:36.337427-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:36.337737-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:36.338040-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:36.338342-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:36.338633-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:36.338921-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:36.339208-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:36.339489-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:36.339793-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:19:36.340542-0500 | compress_modules | INFO - Quantizing model.layers.20.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:19:37.382128-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:19:37.383293-0500 | compress | METRIC - error 15.36\n",
      "2025-11-29T00:19:37.384196-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:37.384732-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:37.385116-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:37.385460-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:37.385942-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:37.386421-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:37.386919-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:37.387412-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:37.387906-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:19:37.389352-0500 | compress_modules | INFO - Quantizing model.layers.20.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:19:38.455476-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:19:38.456910-0500 | compress | METRIC - error 0.50\n",
      "2025-11-29T00:19:38.457599-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:38.457916-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:38.458216-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:38.458530-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:38.458806-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:38.459105-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:38.459389-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:38.459669-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:38.460361-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:19:38.460827-0500 | compress_modules | INFO - Quantizing model.layers.20.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:19:39.600989-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:19:39.602547-0500 | compress | METRIC - error 94.77\n",
      "2025-11-29T00:19:39.603185-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:39.603653-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:39.603955-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:39.604285-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:39.604608-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:39.604907-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:39.605201-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:39.605473-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:39.605780-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:19:39.606537-0500 | compress_modules | INFO - Quantizing model.layers.20.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:19:40.724328-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:19:40.725668-0500 | compress | METRIC - error 45.23\n",
      "2025-11-29T00:19:40.726293-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:40.726587-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:40.726879-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:40.727197-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:40.727472-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:40.727783-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:40.728050-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:40.728348-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:40.728656-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:19:40.729409-0500 | compress_modules | INFO - Quantizing model.layers.20.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:19:43.703342-0500 | compress | METRIC - time 2.97s\n",
      "2025-11-29T00:19:43.704983-0500 | compress | METRIC - error 3.32\n",
      "2025-11-29T00:19:43.705885-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:43.706194-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:43.706498-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:43.706776-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:43.707311-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:43.707608-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:43.707876-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:19:43.708157-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:43.708472-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(21/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 174.00it/s]\n",
      "(22/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:19:56.775919-0500 | compress_modules | INFO - Quantizing model.layers.21.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:19:57.873580-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:19:57.874822-0500 | compress | METRIC - error 197.36\n",
      "2025-11-29T00:19:57.875846-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:57.876175-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:57.876545-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:57.876872-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:57.877175-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:57.877512-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:57.877859-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:57.878187-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:57.878535-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:19:57.879485-0500 | compress_modules | INFO - Quantizing model.layers.21.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:19:58.924029-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:19:58.925046-0500 | compress | METRIC - error 182.59\n",
      "2025-11-29T00:19:58.925957-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:58.926291-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:58.926575-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:58.926885-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:58.927188-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:58.927475-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:58.927749-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:58.928057-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:58.928730-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:19:58.929177-0500 | compress_modules | INFO - Quantizing model.layers.21.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:19:59.972526-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:19:59.973427-0500 | compress | METRIC - error 20.74\n",
      "2025-11-29T00:19:59.974461-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:59.974878-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:19:59.975244-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:59.975592-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:59.975934-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:19:59.976243-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:59.976572-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:19:59.976923-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:19:59.977257-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:19:59.978134-0500 | compress_modules | INFO - Quantizing model.layers.21.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:20:01.068286-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:20:01.069221-0500 | compress | METRIC - error 0.70\n",
      "2025-11-29T00:20:01.070283-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:01.070779-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:01.071153-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:01.071463-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:01.071854-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:01.072191-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:01.072525-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:01.072847-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:01.073217-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:20:01.074099-0500 | compress_modules | INFO - Quantizing model.layers.21.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:20:02.186887-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:20:02.188014-0500 | compress | METRIC - error 94.25\n",
      "2025-11-29T00:20:02.189144-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:02.189757-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:02.190099-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:02.190440-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:02.190834-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:02.191221-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:02.191542-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:02.191812-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:02.192142-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:20:02.192914-0500 | compress_modules | INFO - Quantizing model.layers.21.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:20:03.305255-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:20:03.306549-0500 | compress | METRIC - error 48.74\n",
      "2025-11-29T00:20:03.307520-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:03.308003-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:03.308330-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:03.308661-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:03.308986-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:03.309322-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:03.309971-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:03.310275-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:03.310619-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:20:03.311232-0500 | compress_modules | INFO - Quantizing model.layers.21.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:20:06.278734-0500 | compress | METRIC - time 2.97s\n",
      "2025-11-29T00:20:06.280285-0500 | compress | METRIC - error 3.30\n",
      "2025-11-29T00:20:06.281174-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:06.281488-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:06.281765-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:06.282062-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:06.282364-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:06.282642-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:06.282940-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:20:06.283242-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:06.283546-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(22/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 168.75it/s]\n",
      "(23/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 51.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:20:19.430798-0500 | compress_modules | INFO - Quantizing model.layers.22.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:20:20.567266-0500 | compress | METRIC - time 1.14s\n",
      "2025-11-29T00:20:20.568370-0500 | compress | METRIC - error 177.84\n",
      "2025-11-29T00:20:20.569311-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:20.569728-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:20.570025-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:20.570338-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:20.570639-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:20.570967-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:20.571279-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:20.571579-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:20.571901-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:20:20.572713-0500 | compress_modules | INFO - Quantizing model.layers.22.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:20:21.677928-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:20:21.679449-0500 | compress | METRIC - error 141.01\n",
      "2025-11-29T00:20:21.680148-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:21.680466-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:21.680782-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:21.681099-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:21.681411-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:21.681707-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:21.681995-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:21.682303-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:21.682623-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:20:21.683501-0500 | compress_modules | INFO - Quantizing model.layers.22.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:20:22.803764-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:20:22.804894-0500 | compress | METRIC - error 20.74\n",
      "2025-11-29T00:20:22.805534-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:22.805817-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:22.806104-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:22.806366-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:22.806871-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:22.807149-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:22.807424-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:22.807682-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:22.807969-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:20:22.808571-0500 | compress_modules | INFO - Quantizing model.layers.22.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:20:23.840299-0500 | compress | METRIC - time 1.03s\n",
      "2025-11-29T00:20:23.841277-0500 | compress | METRIC - error 0.58\n",
      "2025-11-29T00:20:23.842117-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:23.842397-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:23.842680-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:23.842946-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:23.843231-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:23.843515-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:23.844082-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:23.844328-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:23.844636-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:20:23.845154-0500 | compress_modules | INFO - Quantizing model.layers.22.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:20:24.931836-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:20:24.932867-0500 | compress | METRIC - error 103.44\n",
      "2025-11-29T00:20:24.933562-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:24.933856-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:24.934134-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:24.934415-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:24.934665-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:24.934951-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:24.935206-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:24.935508-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:24.935806-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:20:24.936556-0500 | compress_modules | INFO - Quantizing model.layers.22.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:20:26.035881-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:20:26.037003-0500 | compress | METRIC - error 51.18\n",
      "2025-11-29T00:20:26.037897-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:26.038402-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:26.038849-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:26.039272-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:26.039693-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:26.040071-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:26.040467-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:26.040870-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:26.041304-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:20:26.042436-0500 | compress_modules | INFO - Quantizing model.layers.22.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:20:28.911872-0500 | compress | METRIC - time 2.87s\n",
      "2025-11-29T00:20:28.914117-0500 | compress | METRIC - error 3.73\n",
      "2025-11-29T00:20:28.914809-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:28.915147-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:28.915490-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:28.915811-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:28.916108-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:28.916421-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:28.916740-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:20:28.917060-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:28.917399-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(23/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 216.41it/s]\n",
      "(24/29): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 52.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:20:41.025675-0500 | compress_modules | INFO - Quantizing model.layers.23.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:20:42.097288-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:20:42.098135-0500 | compress | METRIC - error 213.48\n",
      "2025-11-29T00:20:42.098783-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:42.099091-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:42.099381-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:42.099658-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:42.099958-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:42.100245-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:42.100513-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:42.100787-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:42.101091-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:20:42.101812-0500 | compress_modules | INFO - Quantizing model.layers.23.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:20:43.117362-0500 | compress | METRIC - time 1.02s\n",
      "2025-11-29T00:20:43.118150-0500 | compress | METRIC - error 183.02\n",
      "2025-11-29T00:20:43.118764-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:43.119049-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:43.119345-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:43.119612-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:43.119882-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:43.120146-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:43.120428-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:43.120696-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:43.120983-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:20:43.121699-0500 | compress_modules | INFO - Quantizing model.layers.23.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:20:44.138802-0500 | compress | METRIC - time 1.02s\n",
      "2025-11-29T00:20:44.139671-0500 | compress | METRIC - error 14.14\n",
      "2025-11-29T00:20:44.140391-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:44.140681-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:44.140973-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:44.141258-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:44.141524-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:44.141791-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:44.142059-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:44.142331-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:44.142606-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:20:44.143338-0500 | compress_modules | INFO - Quantizing model.layers.23.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:20:45.182091-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:20:45.182991-0500 | compress | METRIC - error 0.98\n",
      "2025-11-29T00:20:45.183612-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:45.183887-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:45.184177-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:45.184443-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:45.184712-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:45.184977-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:45.185278-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:45.185539-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:45.185829-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:20:45.186547-0500 | compress_modules | INFO - Quantizing model.layers.23.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:20:46.267769-0500 | compress | METRIC - time 1.08s\n",
      "2025-11-29T00:20:46.268952-0500 | compress | METRIC - error 115.65\n",
      "2025-11-29T00:20:46.269522-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:46.269801-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:46.270103-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:46.270375-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:46.270658-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:46.270928-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:46.271219-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:46.271483-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:46.271775-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:20:46.272512-0500 | compress_modules | INFO - Quantizing model.layers.23.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:20:47.373366-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:20:47.374368-0500 | compress | METRIC - error 58.68\n",
      "2025-11-29T00:20:47.375276-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:47.375561-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:47.375845-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:47.376115-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:47.376395-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:47.376660-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:47.376932-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:20:47.377192-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:47.377495-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:20:47.378224-0500 | compress_modules | INFO - Quantizing model.layers.23.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:20:50.274150-0500 | compress | METRIC - time 2.90s\n",
      "2025-11-29T00:20:50.275721-0500 | compress | METRIC - error 4.20\n",
      "2025-11-29T00:20:50.276481-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:50.276774-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:20:50.277066-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:50.277326-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:50.277604-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:20:50.277861-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:50.278140-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:20:50.278410-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:20:50.278693-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(24/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 195.69it/s]\n",
      "(25/29): Calibrating: 100%|██████████| 512/512 [00:09<00:00, 53.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:21:02.617093-0500 | compress_modules | INFO - Quantizing model.layers.24.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:21:03.686647-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:21:03.687643-0500 | compress | METRIC - error 192.55\n",
      "2025-11-29T00:21:03.688560-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:03.688879-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:03.689196-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:03.689526-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:03.689856-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:03.690151-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:03.690447-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:03.690752-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:03.693896-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:21:03.695382-0500 | compress_modules | INFO - Quantizing model.layers.24.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:21:04.715426-0500 | compress | METRIC - time 1.02s\n",
      "2025-11-29T00:21:04.716243-0500 | compress | METRIC - error 171.66\n",
      "2025-11-29T00:21:04.717170-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:04.717501-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:04.717815-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:04.718078-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:04.718355-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:04.718636-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:04.718898-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:04.719184-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:04.719469-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:21:04.720301-0500 | compress_modules | INFO - Quantizing model.layers.24.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:21:05.734898-0500 | compress | METRIC - time 1.01s\n",
      "2025-11-29T00:21:05.735767-0500 | compress | METRIC - error 32.80\n",
      "2025-11-29T00:21:05.736479-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:05.736771-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:05.737070-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:05.737334-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:05.737620-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:05.737874-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:05.738145-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:05.738621-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:05.738920-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:21:05.739656-0500 | compress_modules | INFO - Quantizing model.layers.24.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:21:06.779541-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:21:06.780380-0500 | compress | METRIC - error 1.06\n",
      "2025-11-29T00:21:06.781243-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:06.781563-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:06.781865-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:06.782159-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:06.782455-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:06.782781-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:06.783082-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:06.783389-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:06.783702-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:21:06.784548-0500 | compress_modules | INFO - Quantizing model.layers.24.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:21:07.886149-0500 | compress | METRIC - time 1.10s\n",
      "2025-11-29T00:21:07.887261-0500 | compress | METRIC - error 129.13\n",
      "2025-11-29T00:21:07.887805-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:07.888086-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:07.888362-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:07.888640-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:07.888895-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:07.889171-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:07.889417-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:07.889690-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:07.889968-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:21:07.890707-0500 | compress_modules | INFO - Quantizing model.layers.24.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:21:08.980990-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:21:08.981911-0500 | compress | METRIC - error 64.20\n",
      "2025-11-29T00:21:08.982503-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:08.982848-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:08.983185-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:08.983491-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:08.983791-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:08.984093-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:08.984398-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:08.984692-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:08.985006-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:21:08.985878-0500 | compress_modules | INFO - Quantizing model.layers.24.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:21:11.879879-0500 | compress | METRIC - time 2.89s\n",
      "2025-11-29T00:21:11.881548-0500 | compress | METRIC - error 5.31\n",
      "2025-11-29T00:21:11.882520-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:11.882850-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:11.883179-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:11.883481-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:11.884045-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:11.884330-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:11.884629-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:21:11.884932-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:11.885265-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(25/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 215.07it/s]\n",
      "(26/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:21:24.464363-0500 | compress_modules | INFO - Quantizing model.layers.25.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:21:25.558652-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:21:25.559544-0500 | compress | METRIC - error 168.59\n",
      "2025-11-29T00:21:25.560194-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:25.560551-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:25.560863-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:25.561146-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:25.561597-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:25.561928-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:25.562168-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:25.562581-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:25.562854-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:21:25.563373-0500 | compress_modules | INFO - Quantizing model.layers.25.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:21:26.594033-0500 | compress | METRIC - time 1.03s\n",
      "2025-11-29T00:21:26.594802-0500 | compress | METRIC - error 107.70\n",
      "2025-11-29T00:21:26.595381-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:26.595700-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:26.596005-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:26.596309-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:26.596605-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:26.596888-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:26.597191-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:26.597520-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:26.597877-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:21:26.598323-0500 | compress_modules | INFO - Quantizing model.layers.25.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:21:27.629560-0500 | compress | METRIC - time 1.03s\n",
      "2025-11-29T00:21:27.630246-0500 | compress | METRIC - error 20.56\n",
      "2025-11-29T00:21:27.630851-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:27.631146-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:27.631586-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:27.631934-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:27.632281-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:27.632539-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:27.632885-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:27.633273-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:27.633610-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:21:27.634024-0500 | compress_modules | INFO - Quantizing model.layers.25.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:21:28.691351-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:21:28.692167-0500 | compress | METRIC - error 1.18\n",
      "2025-11-29T00:21:28.692680-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:28.692982-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:28.693287-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:28.693592-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:28.693880-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:28.694187-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:28.694483-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:28.694784-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:28.695117-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:21:28.695514-0500 | compress_modules | INFO - Quantizing model.layers.25.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:21:29.806288-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:21:29.807204-0500 | compress | METRIC - error 139.34\n",
      "2025-11-29T00:21:29.807879-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:29.808236-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:29.808582-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:29.808859-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:29.809269-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:29.809611-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:29.809972-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:29.810354-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:29.810759-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:21:29.811260-0500 | compress_modules | INFO - Quantizing model.layers.25.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:21:30.922818-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:21:30.923827-0500 | compress | METRIC - error 79.81\n",
      "2025-11-29T00:21:30.924449-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:30.924759-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:30.925063-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:30.925362-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:30.925665-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:30.925960-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:30.926254-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:30.926544-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:30.926861-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:21:30.927270-0500 | compress_modules | INFO - Quantizing model.layers.25.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:21:33.877894-0500 | compress | METRIC - time 2.95s\n",
      "2025-11-29T00:21:33.879347-0500 | compress | METRIC - error 7.13\n",
      "2025-11-29T00:21:33.879947-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:33.880306-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:33.880685-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:33.881019-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:33.881347-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:33.881624-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:33.882024-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:21:33.882274-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:33.882681-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(26/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 164.36it/s]\n",
      "(27/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:21:47.191787-0500 | compress_modules | INFO - Quantizing model.layers.26.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:21:48.280898-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:21:48.281609-0500 | compress | METRIC - error 240.47\n",
      "2025-11-29T00:21:48.282275-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:48.282606-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:48.282949-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:48.283256-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:48.283556-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:48.283851-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:48.284149-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:48.284440-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:48.284739-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:21:48.285123-0500 | compress_modules | INFO - Quantizing model.layers.26.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:21:49.351947-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:21:49.352610-0500 | compress | METRIC - error 209.76\n",
      "2025-11-29T00:21:49.353244-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:49.353611-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:49.353957-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:49.354312-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:49.354635-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:49.355006-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:49.355281-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:49.355674-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:49.355946-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:21:49.356421-0500 | compress_modules | INFO - Quantizing model.layers.26.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:21:50.392957-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:21:50.393637-0500 | compress | METRIC - error 38.99\n",
      "2025-11-29T00:21:50.394258-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:50.394624-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:50.394893-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:50.395343-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:50.395566-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:50.395991-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:50.396324-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:50.396673-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:50.397025-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:21:50.397445-0500 | compress_modules | INFO - Quantizing model.layers.26.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:21:51.466874-0500 | compress | METRIC - time 1.07s\n",
      "2025-11-29T00:21:51.467742-0500 | compress | METRIC - error 2.14\n",
      "2025-11-29T00:21:51.468412-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:51.468730-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:51.469053-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:51.469357-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:51.469665-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:51.469962-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:51.470282-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:51.470565-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:51.470889-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:21:51.472171-0500 | compress_modules | INFO - Quantizing model.layers.26.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:21:52.600661-0500 | compress | METRIC - time 1.13s\n",
      "2025-11-29T00:21:52.601872-0500 | compress | METRIC - error 138.05\n",
      "2025-11-29T00:21:52.602824-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:52.603430-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:52.603722-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:52.604010-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:52.604327-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:52.604613-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:52.604896-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:52.605173-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:52.605471-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:21:52.606252-0500 | compress_modules | INFO - Quantizing model.layers.26.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:21:53.730156-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:21:53.731424-0500 | compress | METRIC - error 86.05\n",
      "2025-11-29T00:21:53.732502-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:53.733093-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:53.733675-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:53.734206-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:53.734674-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:53.735155-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:53.735613-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:21:53.736063-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:53.736544-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:21:53.737951-0500 | compress_modules | INFO - Quantizing model.layers.26.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:21:56.696854-0500 | compress | METRIC - time 2.96s\n",
      "2025-11-29T00:21:56.698982-0500 | compress | METRIC - error 10.77\n",
      "2025-11-29T00:21:56.700258-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:56.700865-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:21:56.701421-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:56.701928-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:56.702396-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:21:56.702844-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:56.703325-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:21:56.703809-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:21:56.704350-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(27/29): Propagating: 100%|██████████| 512/512 [00:02<00:00, 178.45it/s]\n",
      "(28/29): Calibrating: 100%|██████████| 512/512 [00:10<00:00, 50.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:22:09.796937-0500 | compress_modules | INFO - Quantizing model.layers.27.self_attn.q_proj using 512 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:22:10.892287-0500 | compress | METRIC - time 1.09s\n",
      "2025-11-29T00:22:10.893179-0500 | compress | METRIC - error 132.17\n",
      "2025-11-29T00:22:10.894020-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:10.894315-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:22:10.894597-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:10.894881-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:10.895195-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:10.895461-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:10.895743-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:22:10.896009-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:10.896304-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:22:10.897082-0500 | compress_modules | INFO - Quantizing model.layers.27.self_attn.k_proj using 512 samples\n",
      "2025-11-29T00:22:11.959636-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:22:11.960532-0500 | compress | METRIC - error 92.50\n",
      "2025-11-29T00:22:11.961140-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:11.961440-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:22:11.961747-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:11.962027-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:11.962292-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:11.962588-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:11.962877-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:22:11.963158-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:11.963454-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:22:11.964215-0500 | compress_modules | INFO - Quantizing model.layers.27.self_attn.v_proj using 512 samples\n",
      "2025-11-29T00:22:13.006490-0500 | compress | METRIC - time 1.04s\n",
      "2025-11-29T00:22:13.007417-0500 | compress | METRIC - error 30.53\n",
      "2025-11-29T00:22:13.008038-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:13.008335-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:22:13.008639-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:13.008914-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:13.009190-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:13.009460-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:13.009729-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:22:13.010006-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:13.010290-0500 | compress | METRIC - Compressed module size: 6.294528 MB\n",
      "2025-11-29T00:22:13.011058-0500 | compress_modules | INFO - Quantizing model.layers.27.self_attn.o_proj using 512 samples\n",
      "2025-11-29T00:22:14.068927-0500 | compress | METRIC - time 1.06s\n",
      "2025-11-29T00:22:14.069989-0500 | compress | METRIC - error 6.06\n",
      "2025-11-29T00:22:14.070943-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:14.071529-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:22:14.072111-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:14.072586-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:14.073044-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:14.073495-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:14.073963-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:22:14.074415-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:14.074909-0500 | compress | METRIC - Compressed module size: 18.883584 MB\n",
      "2025-11-29T00:22:14.076297-0500 | compress_modules | INFO - Quantizing model.layers.27.mlp.gate_proj using 512 samples\n",
      "2025-11-29T00:22:15.188689-0500 | compress | METRIC - time 1.11s\n",
      "2025-11-29T00:22:15.189810-0500 | compress | METRIC - error 113.64\n",
      "2025-11-29T00:22:15.190804-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:15.191333-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:22:15.192065-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:15.192545-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:15.193018-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:15.193494-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:15.193951-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:22:15.194400-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:15.194884-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:22:15.196134-0500 | compress_modules | INFO - Quantizing model.layers.27.mlp.up_proj using 512 samples\n",
      "2025-11-29T00:22:16.313857-0500 | compress | METRIC - time 1.12s\n",
      "2025-11-29T00:22:16.315183-0500 | compress | METRIC - error 116.45\n",
      "2025-11-29T00:22:16.315904-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:16.316208-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:22:16.316493-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:16.316782-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:16.317063-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:16.317346-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:16.317604-0500 | compress | METRIC - GPU 6 | usage: 4.56% | total memory: 51 GB\n",
      "2025-11-29T00:22:16.317886-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:16.318200-0500 | compress | METRIC - Compressed module size: 50.356224 MB\n",
      "2025-11-29T00:22:16.318969-0500 | compress_modules | INFO - Quantizing model.layers.27.mlp.down_proj using 512 samples\n",
      "2025-11-29T00:22:19.273545-0500 | compress | METRIC - time 2.95s\n",
      "2025-11-29T00:22:19.275194-0500 | compress | METRIC - error 29.59\n",
      "2025-11-29T00:22:19.276274-0500 | compress | METRIC - GPU 0 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:19.276770-0500 | compress | METRIC - GPU 1 | usage: 72.85% | total memory: 51 GB\n",
      "2025-11-29T00:22:19.277242-0500 | compress | METRIC - GPU 2 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:19.277725-0500 | compress | METRIC - GPU 3 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:19.278191-0500 | compress | METRIC - GPU 4 | usage: 92.32% | total memory: 51 GB\n",
      "2025-11-29T00:22:19.278648-0500 | compress | METRIC - GPU 5 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:19.279125-0500 | compress | METRIC - GPU 6 | usage: 5.08% | total memory: 51 GB\n",
      "2025-11-29T00:22:19.279590-0500 | compress | METRIC - GPU 7 | usage: 1.22% | total memory: 51 GB\n",
      "2025-11-29T00:22:19.280072-0500 | compress | METRIC - Compressed module size: 50.340864 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(28/29): Propagating: 100%|██████████| 512/512 [00:03<00:00, 167.53it/s]\n",
      "(29/29): Calibrating: 100%|██████████| 512/512 [00:04<00:00, 108.21it/s]\n",
      "(29/29): Propagating: 100%|██████████| 512/512 [00:04<00:00, 113.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-29T00:22:31.887897-0500 | finalize | INFO - Compression lifecycle finalized for 2 modifiers\n",
      "2025-11-29T00:22:31.921459-0500 | post_process | WARNING - Optimized model is not saved. To save, please provide`output_dir` as input arg.Ex. `oneshot(..., output_dir=...)`\n",
      "\n",
      "========== SAMPLE GENERATION ==============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Hello my name is Lorna and I am the new chair of the PTA. I have been a governor at the school for the last 5 years and have been a parent at the school for the last 12 years. I am looking forward to working with the\n",
      "==========================================\n",
      "\n",
      "Saving to /mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8...\n",
      "2025-11-29T00:22:46.394808-0500 | get_model_compressor | INFO - skip_sparsity_compression_stats set to True. Skipping sparsity compression statistic calculations. No sparsity compressor will be applied.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing model: 196it [00:02, 65.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Quantization complete: /mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8\n",
      "Using newly quantized model from: /mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8\n",
      "INFO 11-29 00:23:34 [utils.py:233] non-default args: {'trust_remote_code': True, 'max_model_len': 2048, 'gpu_memory_utilization': 0.7, 'disable_log_stats': True, 'model': '/mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-29 00:23:51 [model.py:547] Resolved architecture: LlamaForCausalLM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-29 00:23:51 [model.py:1510] Using max model len 2048\n",
      "INFO 11-29 00:23:51 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "WARNING 11-29 00:23:52 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized\n",
      "INFO 11-29 00:23:58 [__init__.py:216] Automatically detected platform cuda.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:01 [core.py:644] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:01 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='/mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8', speculative_config=None, tokenizer='/mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=compressed-tensors, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=/mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\",\"vllm.sparse_attn_indexer\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":[2,1],\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"use_inductor_graph_partition\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W1129 00:24:04.729509103 socket.cpp:755] [c10d] The client socket cannot be initialized to connect to [seahorse.cs.columbia.edu]:58643 (errno: 97 - Address family not supported by protocol).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:04 [parallel_state.py:1208] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m WARNING 11-29 00:24:05 [topk_topp_sampler.py:66] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:05 [gpu_model_runner.py:2602] Starting to load model /mnt/swordfish-pool2/kavin/cache/Llama-3.2-3B_int8...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:05 [gpu_model_runner.py:2634] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:05 [compressed_tensors_w8a8_int8.py:52] Using CutlassScaledMMLinearKernel for CompressedTensorsW8A8Int8\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:05 [cuda.py:366] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.21it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  2.21it/s]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:06 [default_loader.py:267] Loading weights took 0.51 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:06 [gpu_model_runner.py:2653] Model loading took 4.1556 GiB and 0.799675 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:16 [backends.py:548] Using cache directory: /home/kr3131/.cache/vllm/torch_compile_cache/50602ae5b4/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:16 [backends.py:559] Dynamo bytecode transform time: 9.26 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:20 [backends.py:197] Cache the graph for dynamic shape for later use\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:39 [backends.py:218] Compiling a graph for dynamic shape takes 22.74 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:44 [monitor.py:34] torch.compile takes 32.00 s in total\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:45 [gpu_worker.py:298] Available KV cache memory: 27.77 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:45 [kv_cache_utils.py:1087] GPU KV cache size: 259,952 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:45 [kv_cache_utils.py:1091] Maximum concurrency for 2,048 tokens per request: 126.93x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:01<00:00, 35.13it/s]\n",
      "Capturing CUDA graphs (decode, FULL): 100%|██████████| 35/35 [00:01<00:00, 33.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:49 [gpu_model_runner.py:3480] Graph capturing finished in 4 secs, took 0.65 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=2533580)\u001b[0;0m INFO 11-29 00:24:49 [core.py:210] init engine (profile, create kv cache, warmup model) took 42.85 seconds\n",
      "INFO 11-29 00:24:50 [llm.py:306] Supported_tasks: ['generate']\n",
      "✓ Model loaded successfully\n",
      "GPU Memory: 4.10GB allocated | 4.63GB reserved | 47.40GB total\n",
      "\n",
      "============================================================\n",
      "LATENCY & MEMORY BENCHMARK\n",
      "============================================================\n",
      "Warmup: 10 | Benchmark: 100 | Batch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Latency/Memory:   0%|          | 0/110 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5812070081454a64b678842d0f5e7891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ba9889d16a45d9acda34d71c98619a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Latency/Memory:   1%|          | 1/110 [00:00<01:08,  1.58it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa0c0d2958a4707a69038cec0db7389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ec3ab5f1354cc3b7465db04aefb3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Latency/Memory:  30%|███       | 33/110 [00:01<00:02, 32.31it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc9e57a9e5224f8db6c490bf55669fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2b2f2b1ff347b09a6a5e5b56418ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/32 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Latency/Memory:  59%|█████▉    | 65/110 [00:01<00:01, 42.92it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6003a2766e42b393a0f720c2790895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985f0ebfe377412eb6039542e28df8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/14 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Latency/Memory: 100%|██████████| 110/110 [00:02<00:00, 47.48it/s]\n",
      "[codecarbon WARNING @ 00:24:52] Multiple instances of codecarbon are allowed to run at the same time.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Latency: 0.0120s | Memory: 4202.39MB\n",
      "\n",
      "============================================================\n",
      "ENERGY CONSUMPTION BENCHMARK\n",
      "============================================================\n",
      "Running 100 inference samples with energy tracking...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon WARNING @ 00:24:54] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. \n",
      " Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU\n",
      "\n",
      "[codecarbon WARNING @ 00:24:54] No CPU tracking mode found. Falling back on CPU load mode.\n",
      "[codecarbon WARNING @ 00:24:54] You have 8 GPUs but we will monitor only 1 ([6]) of them. Check your configuration.\n",
      "Energy tracking:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c78f40a3fcc48098c229b1574407412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae896a9a24c40fcacd704a836226450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   1%|          | 1/100 [00:00<00:25,  3.83it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc70bc16ea464185965a1db352807b94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3656095a0945efadd74aa8af88f8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   2%|▏         | 2/100 [00:00<00:25,  3.83it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8552f1d2e37a4fb6a14db505db168783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30c8a6be8994a0fa44c92631b7210cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   3%|▎         | 3/100 [00:00<00:25,  3.83it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f666d7d370bf4cfb89ceb4c475927cb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505383bf3a694291a79497fa8639abf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   4%|▍         | 4/100 [00:01<00:25,  3.83it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aed898253054911b6fa7b2fc3f7ea46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbeafb1daeeb4f0d9b57f51feecc0731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   5%|▌         | 5/100 [00:01<00:24,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dba7a35c67444729b52190eb74d368e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0209dc0aec8149eeb426e570ee6daf28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   6%|▌         | 6/100 [00:01<00:24,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff98b803c00443a8908f490b76e57ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78eb3a425bb4c19b0e6f07641741b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   7%|▋         | 7/100 [00:01<00:24,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6474d03d693746359afa2180be241240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a9528fe1b04530a5b0a97e3eaa042f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   8%|▊         | 8/100 [00:02<00:23,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15951a523cb549b18afe864f1517e0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34054ef0ce8e4767af80052a81d8d1b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:   9%|▉         | 9/100 [00:02<00:23,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7966106b81ff42b0baf4096c7575a667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9670236c1a144a2193b9ed88f3cfedab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  10%|█         | 10/100 [00:02<00:23,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c2e36a54924cfc874e87030f5aa2a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1ff36b77f04d1bb47aee3818e5ba15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  11%|█         | 11/100 [00:02<00:23,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a731844589f7477491c224774211bbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4d85b7c0c347b98618e6c2e654e5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  12%|█▏        | 12/100 [00:03<00:22,  3.83it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6632cb12e14fb7a8b31273b81577c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75f5347241594a4b8cc8d12b78e41671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  13%|█▎        | 13/100 [00:03<00:22,  3.83it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82f2b512b96a476f9deea506aedec2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df524e2991514d77a035cd1c1bc856dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  14%|█▍        | 14/100 [00:03<00:22,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fce8544c5724db7be5fcdbb5eeb4629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22597a4f394e48edb20b3e931a158703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  15%|█▌        | 15/100 [00:03<00:22,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c0ed8bbde144e58042c134a2a44e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc8ea06780b414788afb33150b2e431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  16%|█▌        | 16/100 [00:04<00:21,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476ecc90270943f5893ef500d38d699c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98ccef1692e4079aa3e17aba81dc212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  17%|█▋        | 17/100 [00:04<00:21,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a01f148b354c9bb3a2841c0dc6b241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b45743b8b144d0a5dfb074851190bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  18%|█▊        | 18/100 [00:04<00:21,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2512d317d3a14d14b3a3ea78b5368846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1744ec45c394c2ea1f215f9a6f8a76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  19%|█▉        | 19/100 [00:04<00:20,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e31007b55eb0453cbaa9bb8383632ff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4d42258daa4e2fa83e6a2c641c15cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  20%|██        | 20/100 [00:05<00:20,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a9a92af116488f840628e8b5dd44f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201b8a10728544dfb8446a1c3b6f6f55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  21%|██        | 21/100 [00:05<00:20,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c19ee0f6fad4172be243d34bbfb114c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ff36cee2484b1f92e638d07cdeb793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  22%|██▏       | 22/100 [00:05<00:20,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d4cf2886b441348ae0b7b1b58fda61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38778315b185464aad58eae8b1b91d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  23%|██▎       | 23/100 [00:05<00:20,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86521431c141409b8d35f0604ebb48ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72263c0adcd41a4bd6a414fd256419a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  24%|██▍       | 24/100 [00:06<00:19,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d809f36f23b48998ac021fa471b8f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1a75913fac43a590ec3698899d58bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  25%|██▌       | 25/100 [00:06<00:19,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3f6eb15f604aae903bccbac8f9a90f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6f05ef94ce4694b4b0ffe0ff4d7beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  26%|██▌       | 26/100 [00:06<00:19,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f8e66d962d14d389ea5a91c18b5664e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f947de8179574a48a7cdd75b1fc244c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  27%|██▋       | 27/100 [00:07<00:19,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92399cd6b8b04eeba8f3c9582b2732e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ed9932b4cf4855a8d0974f79357764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  28%|██▊       | 28/100 [00:07<00:18,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "604a8f209b9e48068ceb20b794ff2b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dca40a0c515443f69c70568b9a85e04d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  29%|██▉       | 29/100 [00:07<00:18,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabf2bbc162e4b43a8ab605fd9d46669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3269b53f0c9c4153a8e11ab1bc1a8e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  30%|███       | 30/100 [00:07<00:18,  3.83it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6859219106cf4617a7be4d00e669d3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a834f5b661a49a8819222899f16d4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  31%|███       | 31/100 [00:08<00:18,  3.83it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33e29381a654effb9cfb410f9c7fe7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1743a54b11c64655aa34f8b36bcd6824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  32%|███▏      | 32/100 [00:08<00:17,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9952b701870b41c189d2424fb89f0e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addab011d85645de8f576f42a49aedea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  33%|███▎      | 33/100 [00:08<00:17,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017bb5edca1f4ae48669ea356b5b14ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "132e01cc4561461c983f2c69e6a7b831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  34%|███▍      | 34/100 [00:08<00:17,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a51e147f5fbb4b00b322b3360c0021db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6958695f6143afb0e4c49e5150fa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  35%|███▌      | 35/100 [00:09<00:16,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4fb8fb05afa44a0946ceb3bfbc36c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b784a1231344626889c4287d0fee548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  36%|███▌      | 36/100 [00:09<00:16,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da81d7407ea54309bd436dbb8eac084c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19c3893780744f0dbaf3b26d55c46ca7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  37%|███▋      | 37/100 [00:09<00:16,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a124d90872944ad9203c3b2a4a9de00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc76db8c25549fb8d02d774cf23b754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  38%|███▊      | 38/100 [00:09<00:16,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac540eca9703447fa7eb1bd4e8eebd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea04715f761428cb6819f5b7ac39069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  39%|███▉      | 39/100 [00:10<00:15,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d353eb806efb4c538c8f6951a771be35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548bf67c62c744429ed4a6fa54b89fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  40%|████      | 40/100 [00:10<00:15,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d69c7aa8624e30b52c8530df214ba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f33d3d88e98c4cf4baef9f57dcea001e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  41%|████      | 41/100 [00:10<00:15,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c11641f57ed4eaf934a1cd1665cc94b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd678c91f174ffc8147aefc02e060d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  42%|████▏     | 42/100 [00:10<00:15,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e84da62400324c99a2d9838d21e32358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66399967aa24cb783670bd821dd7369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  43%|████▎     | 43/100 [00:11<00:14,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fc19bf7955d46849e571a9b0cd94561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac64bac205ce473dbe6297d143b589f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  44%|████▍     | 44/100 [00:11<00:14,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b0625084714784a7547d43df1c21db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0fe1a69ac2e4d51b3e55f79d5d0a398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  45%|████▌     | 45/100 [00:11<00:14,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdd4a99d7b84060abf8468042ccf617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f058fdb52c2a43d7bf48ac6af64cfea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  46%|████▌     | 46/100 [00:11<00:14,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a88c19d786f4aa7ab119a5d2d55388d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7490f41390664a7f9b108653e72e2c46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  47%|████▋     | 47/100 [00:12<00:13,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1c39606ac6420089b1cadca245b3e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f43413f9f0c4ddf8fdbb47bbefb1217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  48%|████▊     | 48/100 [00:12<00:13,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c9e9afe6744842b30a6cb90051c33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b4e6567d8146539ebb928f0de46c94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  49%|████▉     | 49/100 [00:12<00:13,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c841d084d114ffdab736f150e96c741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6436db866586420aa7fd7a693a1a6af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  50%|█████     | 50/100 [00:13<00:13,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d259671a4274b6f92bc5904e561d49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb01a1ae48443b0bde013602a611263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  51%|█████     | 51/100 [00:13<00:12,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0f75ed5d804ed98d9ceec41d17af1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29b592077a544457ab03eaab3ae8ab53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  52%|█████▏    | 52/100 [00:13<00:12,  3.84it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "748618e0df874fe0baddd7a4d9ee77ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd2b73209434d7fae2d4839745bf1a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  53%|█████▎    | 53/100 [00:13<00:12,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4e6fe82bcd4e90b599952e31f8b8db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03916debee364481b8232726b1e2d470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  54%|█████▍    | 54/100 [00:14<00:11,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470f41f506aa41bc811ea9792a50b94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3baae079ba464de7ac1fdde4a36868e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  55%|█████▌    | 55/100 [00:14<00:11,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc66c27f9f64650a57fba9476009e8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b029c40d4e814ea68c99e6b843abd946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  56%|█████▌    | 56/100 [00:14<00:11,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901ad25924f64e8dbe4b6e469f32aac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "161d7e721b8f4715b7a54ae3c6100823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  57%|█████▋    | 57/100 [00:14<00:11,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7310055f7a9f4f52b4aa3a9fd46a8fb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a32ebfb971443b1ac44c8765a180c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  58%|█████▊    | 58/100 [00:15<00:10,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a1428cf54fa4ca28d657b2dfd03570e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8c01af88a24b6dbfe66b2d3e7f5c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  59%|█████▉    | 59/100 [00:15<00:10,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e3f0903f494e0ea7f0c16214e7e36a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd48b798b5bb443b890fe34e0de8f77c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  60%|██████    | 60/100 [00:15<00:10,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09920a7282b14b53b58809b21037374e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fabb7cdcf2540bf92b4a0ef7e32d6ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  61%|██████    | 61/100 [00:15<00:10,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6549cd1dd139477eb335b11e38c8d32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e9cf10601f42b28619f8b96e3ed383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  62%|██████▏   | 62/100 [00:16<00:09,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e3c36901d5d4566b4e548b5caaf4429",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62b916e5117f440dbf2b9f30fdaccb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  63%|██████▎   | 63/100 [00:16<00:09,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581c306847e64d7ba1838bfd172e65a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2845b393dfa04d439f85aef64492dcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  64%|██████▍   | 64/100 [00:16<00:09,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7194c453143c4116a4b2a2572326f093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2c40f970b047eeb4452aea64c4f0c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  65%|██████▌   | 65/100 [00:16<00:09,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cac3c394e0470a8bd28f4da7469fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c817a68352d4a4894bb3266966229fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  66%|██████▌   | 66/100 [00:17<00:08,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e872daf460014e8a89f28b5ecf1bd4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc95a26cbeb4c24b23ac506f3b56be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  67%|██████▋   | 67/100 [00:17<00:08,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fabb31134f45dd8f18a4c66b92695b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0512b6aa9be14287a7134cdb44d24066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  68%|██████▊   | 68/100 [00:17<00:08,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003abb440f8142e3bf0778e6f346785a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4166ec1e8034459a87a96ad2ef1172f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  69%|██████▉   | 69/100 [00:17<00:08,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0705e5cc5c9348f0b5f51c044acf4d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75835212567644c9899f3b3dc3c881ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  70%|███████   | 70/100 [00:18<00:07,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a58b40c15704b6d86ce493a11a6a265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdde1eea1d6645c09034a759801a5195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  71%|███████   | 71/100 [00:18<00:07,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593a6e3a97ad4b3a92bfd755fe3db193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c391a94fe9b541ddaeb27f6277309bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  72%|███████▏  | 72/100 [00:18<00:07,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bda50747f14411ac5fcad557fe707a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a787ad3ae54042e1965c484d561b40f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  73%|███████▎  | 73/100 [00:18<00:07,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa8fab651754d45adacaed79a55d0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d4cbf4a2cb43669f813cf8324baac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  74%|███████▍  | 74/100 [00:19<00:06,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60595dcaabdb4e50b04ffa2852d18b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc28fb96d85a439c80a2463dc91bcb7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  75%|███████▌  | 75/100 [00:19<00:06,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dec18b51ee64a08bc4295a816d1d10c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c022c4334448a6a81031040f302038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  76%|███████▌  | 76/100 [00:19<00:06,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df9bc66b3d04bb8a9d6d79e8ebc3d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e737f08680654a1cb1c6705068b46b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  77%|███████▋  | 77/100 [00:20<00:05,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3386d0341544b72b835cfc4ed1d29f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfefbd56210c439bbcb2ff409ff247c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  78%|███████▊  | 78/100 [00:20<00:05,  3.85it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f786697bd44e78a60edabbf2f8fb85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cbf0897dec54af8af78a293159ef962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  79%|███████▉  | 79/100 [00:20<00:05,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab44d00fafea468baefefd558b852804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a14793da8c44f44b82d546f42ad4aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  80%|████████  | 80/100 [00:20<00:05,  3.88it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "769452f87d674549b02dfcbca26adf14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771fa6cd40794901ac6a3d6121ec23f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  81%|████████  | 81/100 [00:21<00:04,  3.89it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df369fe87484489b509684a37e0110a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3286c183df534b26835a0654cb14b109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  82%|████████▏ | 82/100 [00:21<00:04,  3.88it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6c3d969e5b473bbdadae99161f993e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab634ebf7484ebdb1310792d05b32ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  83%|████████▎ | 83/100 [00:21<00:04,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7555db6af344b8c8c98363d25ebf2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e680e6c8f744ccaaf7512d9fa85af75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  84%|████████▍ | 84/100 [00:21<00:04,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16ad926cd9b54feb883921994f21d915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2b5713170b40a6a8729a3e78cd8928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  85%|████████▌ | 85/100 [00:22<00:03,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88868d8c956d43a0b98fba76fb6b444d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1350c5cbf6c4df183eb90ab0a66e44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  86%|████████▌ | 86/100 [00:22<00:03,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af9e008f94f4a1990ec286c5917336d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4a58bb4ef734c7480ff33a3d39568fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  87%|████████▋ | 87/100 [00:22<00:03,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436530a2a53e4da5892c2931041203ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a26d763248445e904575a14fcbd4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  88%|████████▊ | 88/100 [00:22<00:03,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28fc745dff764c12b1b88244eeb60df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1aac6b015f5429f86b883bd3a2e46ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  89%|████████▉ | 89/100 [00:23<00:02,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9caee4379774595ba913eaf8a4db936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738044d2a4624412865ce41b9682bb9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  90%|█████████ | 90/100 [00:23<00:02,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f327dab56a004f04b8b7e9df6811ea71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d4fb3bfb8254c7ba67ea7e497e42f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  91%|█████████ | 91/100 [00:23<00:02,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eaeb0b3b4c2484799b8bd6531ae7b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe7f732854446018531633e49e226f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  92%|█████████▏| 92/100 [00:23<00:02,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a1ab1f38374e8f90af2f4c6a5ff877",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee96d3890364263a9c25337412e8812",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  93%|█████████▎| 93/100 [00:24<00:01,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d390958a011b4fd4a4f7f7fc33c69a6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198ddc269b8f414491d876d52507e8dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  94%|█████████▍| 94/100 [00:24<00:01,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bde968084f24ad4a495c296f8c9dc22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f3cbad9253448d808827f36cc7c3bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  95%|█████████▌| 95/100 [00:24<00:01,  3.86it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0b4932e69148b2a37b175ab1140903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe6ffd310a24e91b82a44391349d093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  96%|█████████▌| 96/100 [00:24<00:01,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa4467f41fc4452ad172930768e1fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e70b62e327046549f542e924ef15baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  97%|█████████▋| 97/100 [00:25<00:00,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67eac6afd90240e694a13ed9028f78f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7802f1182b44dd8f0063a2fac60d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  98%|█████████▊| 98/100 [00:25<00:00,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249dac60238b4aaa8075db75e5aa98fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "077ae02c0a644f99a89faebcf1db59f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking:  99%|█████████▉| 99/100 [00:25<00:00,  3.87it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2133f0f821044f828c06226cdd522296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4427418410584bd2a6ad0ddf05d1b5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Energy tracking: 100%|██████████| 100/100 [00:25<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Energy: 0.5458 Wh | Avg Power: 75.68W\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank0]:[W1129 00:25:24.317380608 ProcessGroupNCCL.cpp:1538] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results saved for Llama-3.2-3B_int8\n",
      "\n",
      "######################################################################\n",
      "ALL BENCHMARKS COMPLETE!\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'#' * 70}\")\n",
    "print(\"SLiM-Eval: COMPLETE BENCHMARK SUITE\")\n",
    "print(f\"{'#' * 70}\\n\")\n",
    "print(f\"Models: {len(MODELS)}\")\n",
    "print(f\"Precisions: {PRECISIONS}\")\n",
    "print(f\"Total configs: {len(MODELS) * len(PRECISIONS)}\")\n",
    "print(f\"Metrics: Latency, Memory, Energy, Accuracy\")\n",
    "print(f\"Output: {RESULTS_CSV}\")\n",
    "print(f\"\\nEstimated time: ~{len(MODELS) * len(PRECISIONS) * 30} minutes\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for model_name in MODELS:\n",
    "    for precision in PRECISIONS:\n",
    "        config_id = f\"{model_name.split('/')[-1]}_{precision}\"\n",
    "\n",
    "        # Run complete benchmark\n",
    "        results = run_complete_benchmark(model_name, precision)\n",
    "\n",
    "        if results:\n",
    "            all_results.append(results)\n",
    "\n",
    "            # Save incrementally\n",
    "            pd.DataFrame([results]).to_csv(\n",
    "                RESULTS_CSV, mode=\"a\", header=False, index=False\n",
    "            )\n",
    "            print(f\"\\n✓ Results saved for {config_id}\")\n",
    "\n",
    "        # Cleanup between configs\n",
    "        clear_cache()\n",
    "        time.sleep(5)\n",
    "\n",
    "print(f\"\\n{'#' * 70}\")\n",
    "print(\"ALL BENCHMARKS COMPLETE!\")\n",
    "print(f\"{'#' * 70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9dd566",
   "metadata": {},
   "source": [
    "## Cell 14: Load and Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eead64a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "COMPLETE RESULTS SUMMARY\n",
      "######################################################################\n",
      "\n",
      "                  model precision  mean_latency_s  mean_peak_mem_mb  energy_kwh  avg_power_watts  mmlu_accuracy  gsm8k_accuracy  hellaswag_accuracy\n",
      "meta-llama/Llama-3.2-3B      int8           0.012         4202.3931      0.0005          75.6789        19.6506             NaN                 NaN\n",
      "\n",
      "✓ Full results: slim_eval_results/complete_results.csv\n"
     ]
    }
   ],
   "source": [
    "# Load complete results\n",
    "results_df = pd.read_csv(RESULTS_CSV)\n",
    "\n",
    "print(f\"\\n{'#' * 70}\")\n",
    "print(\"COMPLETE RESULTS SUMMARY\")\n",
    "print(f\"{'#' * 70}\\n\")\n",
    "\n",
    "# Display key metrics\n",
    "display_columns = [\n",
    "    \"model\",\n",
    "    \"precision\",\n",
    "    \"mean_latency_s\",\n",
    "    \"mean_peak_mem_mb\",\n",
    "    \"energy_kwh\",\n",
    "    \"avg_power_watts\",\n",
    "] + [col for col in results_df.columns if \"accuracy\" in col]\n",
    "\n",
    "print(results_df[display_columns].round(4).to_string(index=False))\n",
    "\n",
    "print(f\"\\n✓ Full results: {RESULTS_CSV}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e04a6c",
   "metadata": {},
   "source": [
    "## Cell 15: Analysis - Efficiency vs Accuracy Trade-offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6041b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate efficiency metrics\n",
    "analysis_results = []\n",
    "\n",
    "for model in results_df[\"model\"].unique():\n",
    "    model_data = results_df[results_df[\"model\"] == model]\n",
    "    fp16_data = model_data[model_data[\"precision\"] == \"fp16\"]\n",
    "\n",
    "    if len(fp16_data) == 0:\n",
    "        continue\n",
    "\n",
    "    fp16_latency = fp16_data[\"mean_latency_s\"].values[0]\n",
    "    fp16_memory = fp16_data[\"mean_peak_mem_mb\"].values[0]\n",
    "    fp16_energy = (\n",
    "        fp16_data[\"energy_joules\"].values[0]\n",
    "        if \"energy_joules\" in fp16_data.columns\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    for _, row in model_data.iterrows():\n",
    "        if row[\"precision\"] != \"fp16\":\n",
    "            analysis_row = {\n",
    "                \"model\": model.split(\"/\")[-1],\n",
    "                \"precision\": row[\"precision\"],\n",
    "                \"speedup\": fp16_latency / row[\"mean_latency_s\"],\n",
    "                \"memory_reduction_pct\": (1 - row[\"mean_peak_mem_mb\"] / fp16_memory)\n",
    "                * 100,\n",
    "            }\n",
    "\n",
    "            # Energy reduction\n",
    "            if \"energy_joules\" in row and fp16_energy > 0:\n",
    "                analysis_row[\"energy_reduction_pct\"] = (\n",
    "                    1 - row[\"energy_joules\"] / fp16_energy\n",
    "                ) * 100\n",
    "\n",
    "            # Accuracy drop\n",
    "            for task in ACCURACY_TASKS:\n",
    "                acc_col = f\"{task}_accuracy\"\n",
    "                if acc_col in fp16_data.columns and acc_col in row:\n",
    "                    fp16_acc = fp16_data[acc_col].values[0]\n",
    "                    quant_acc = row[acc_col]\n",
    "                    if fp16_acc > 0:\n",
    "                        analysis_row[f\"{task}_acc_drop_pct\"] = (\n",
    "                            (fp16_acc - quant_acc) / fp16_acc\n",
    "                        ) * 100\n",
    "\n",
    "            analysis_results.append(analysis_row)\n",
    "\n",
    "if analysis_results:\n",
    "    analysis_df = pd.DataFrame(analysis_results)\n",
    "    print(\"\\n{'#'*70}\")\n",
    "    print(\"QUANTIZATION IMPACT ANALYSIS\")\n",
    "    print(f\"{'#' * 70}\\n\")\n",
    "    print(analysis_df.round(3).to_string(index=False))\n",
    "\n",
    "    analysis_path = OUTPUT_DIR / \"quantization_impact.csv\"\n",
    "    analysis_df.to_csv(analysis_path, index=False)\n",
    "    print(f\"\\n✓ Analysis saved: {analysis_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ceba8c",
   "metadata": {},
   "source": [
    "## Cell 16: Visualization - Pareto Frontiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89ba2de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Visualizations saved: slim_eval_results/pareto_frontiers.png\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Latency vs Memory\n",
    "ax1 = axes[0, 0]\n",
    "for precision in results_df[\"precision\"].unique():\n",
    "    data = results_df[results_df[\"precision\"] == precision]\n",
    "    ax1.scatter(\n",
    "        data[\"mean_latency_s\"],\n",
    "        data[\"mean_peak_mem_mb\"],\n",
    "        label=precision.upper(),\n",
    "        s=150,\n",
    "        alpha=0.7,\n",
    "    )\n",
    "ax1.set_xlabel(\"Latency (seconds)\")\n",
    "ax1.set_ylabel(\"Peak Memory (MB)\")\n",
    "ax1.set_title(\"Latency vs Memory\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Energy vs Accuracy (if available)\n",
    "if \"energy_kwh\" in results_df.columns and any(\n",
    "    \"accuracy\" in col for col in results_df.columns\n",
    "):\n",
    "    ax2 = axes[0, 1]\n",
    "    acc_col = [col for col in results_df.columns if \"accuracy\" in col][0]\n",
    "    for precision in results_df[\"precision\"].unique():\n",
    "        data = results_df[results_df[\"precision\"] == precision]\n",
    "        ax2.scatter(\n",
    "            data[\"energy_kwh\"], data[acc_col], label=precision.upper(), s=150, alpha=0.7\n",
    "        )\n",
    "    ax2.set_xlabel(\"Energy (kWh)\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_title(\"Energy vs Accuracy Trade-off\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Throughput comparison\n",
    "ax3 = axes[1, 0]\n",
    "models_short = results_df[\"model\"].str.split(\"/\").str[-1]\n",
    "for precision in results_df[\"precision\"].unique():\n",
    "    data = results_df[results_df[\"precision\"] == precision]\n",
    "    indices = data.index\n",
    "    ax3.bar(\n",
    "        [models_short[i] for i in indices],\n",
    "        data[\"tokens_per_second\"],\n",
    "        label=precision.upper(),\n",
    "        alpha=0.7,\n",
    "    )\n",
    "ax3.set_xlabel(\"Model\")\n",
    "ax3.set_ylabel(\"Tokens/Second\")\n",
    "ax3.set_title(\"Throughput by Model and Precision\")\n",
    "ax3.legend()\n",
    "ax3.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "# Plot 4: Accuracy comparison across tasks\n",
    "ax4 = axes[1, 1]\n",
    "accuracy_cols = [col for col in results_df.columns if \"accuracy\" in col]\n",
    "if accuracy_cols:\n",
    "    # Average accuracy across all tasks\n",
    "    results_df[\"avg_accuracy\"] = results_df[accuracy_cols].mean(axis=1)\n",
    "    for precision in results_df[\"precision\"].unique():\n",
    "        data = results_df[results_df[\"precision\"] == precision]\n",
    "        indices = data.index\n",
    "        ax4.bar(\n",
    "            [models_short[i] for i in indices],\n",
    "            data[\"avg_accuracy\"],\n",
    "            label=precision.upper(),\n",
    "            alpha=0.7,\n",
    "        )\n",
    "    ax4.set_xlabel(\"Model\")\n",
    "    ax4.set_ylabel(\"Average Accuracy\")\n",
    "    ax4.set_title(\"Average Accuracy Across Tasks\")\n",
    "    ax4.legend()\n",
    "    ax4.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"pareto_frontiers.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Visualizations saved: {OUTPUT_DIR / 'pareto_frontiers.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c6791a",
   "metadata": {},
   "source": [
    "## Cell 17: Summary Statistics Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d734312e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'#'*70}\n",
      "SUMMARY STATISTICS BY PRECISION\n",
      "######################################################################\n",
      "\n",
      "          mean_latency_s                   mean_peak_mem_mb                 \\\n",
      "                    mean std    min    max             mean std        min   \n",
      "precision                                                                    \n",
      "int8               0.012 NaN  0.012  0.012        4202.3931 NaN  4202.3931   \n",
      "\n",
      "                     tokens_per_second                           energy_kwh  \\\n",
      "                 max              mean std        min        max       mean   \n",
      "precision                                                                     \n",
      "int8       4202.3931         2666.0755 NaN  2666.0755  2666.0755     0.0005   \n",
      "\n",
      "              avg_power_watts      \n",
      "          std            mean std  \n",
      "precision                          \n",
      "int8      NaN         75.6789 NaN  \n",
      "\n",
      "✓ Summary saved: slim_eval_results/summary_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive summary\n",
    "summary_stats = (\n",
    "    results_df.groupby([\"precision\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"mean_latency_s\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "            \"mean_peak_mem_mb\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "            \"tokens_per_second\": [\"mean\", \"std\", \"min\", \"max\"],\n",
    "        }\n",
    "    )\n",
    "    .round(4)\n",
    ")\n",
    "\n",
    "if \"energy_kwh\" in results_df.columns:\n",
    "    energy_stats = (\n",
    "        results_df.groupby([\"precision\"])\n",
    "        .agg(\n",
    "            {\n",
    "                \"energy_kwh\": [\"mean\", \"std\"],\n",
    "                \"avg_power_watts\": [\"mean\", \"std\"],\n",
    "            }\n",
    "        )\n",
    "        .round(4)\n",
    "    )\n",
    "    summary_stats = pd.concat([summary_stats, energy_stats], axis=1)\n",
    "\n",
    "print(\"\\n{'#'*70}\")\n",
    "print(\"SUMMARY STATISTICS BY PRECISION\")\n",
    "print(f\"{'#' * 70}\\n\")\n",
    "print(summary_stats)\n",
    "\n",
    "summary_stats.to_csv(OUTPUT_DIR / \"summary_statistics.csv\")\n",
    "print(f\"\\n✓ Summary saved: {OUTPUT_DIR / 'summary_statistics.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d160a5",
   "metadata": {},
   "source": [
    "## Cell 18: Paper-Ready Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9a192ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'#'*70}\n",
      "PAPER-READY RESULTS TABLE\n",
      "######################################################################\n",
      "\n",
      "       model precision  Latency (s)  Memory (MB)  Tokens/s  Energy (kWh)  mmlu_accuracy  gsm8k_accuracy  hellaswag_accuracy\n",
      "Llama-3.2-3B      int8        0.012    4202.3931 2666.0755        0.0005        19.6506             NaN                 NaN\n",
      "\n",
      "✓ Paper table saved: slim_eval_results/paper_results.csv\n",
      "✓ LaTeX table saved: slim_eval_results/paper_results.tex\n"
     ]
    }
   ],
   "source": [
    "# Create formatted table for academic papers\n",
    "paper_columns = [\n",
    "    \"model\",\n",
    "    \"precision\",\n",
    "    \"mean_latency_s\",\n",
    "    \"mean_peak_mem_mb\",\n",
    "    \"tokens_per_second\",\n",
    "]\n",
    "\n",
    "if \"energy_kwh\" in results_df.columns:\n",
    "    paper_columns.append(\"energy_kwh\")\n",
    "\n",
    "accuracy_cols = [col for col in results_df.columns if \"accuracy\" in col]\n",
    "if accuracy_cols:\n",
    "    paper_columns.extend(accuracy_cols[:3])  # Include first 3 accuracy metrics\n",
    "\n",
    "paper_table = results_df[paper_columns].copy()\n",
    "paper_table[\"model\"] = paper_table[\"model\"].str.split(\"/\").str[-1]\n",
    "\n",
    "# Rename columns for readability\n",
    "rename_map = {\n",
    "    \"mean_latency_s\": \"Latency (s)\",\n",
    "    \"mean_peak_mem_mb\": \"Memory (MB)\",\n",
    "    \"tokens_per_second\": \"Tokens/s\",\n",
    "    \"energy_kwh\": \"Energy (kWh)\",\n",
    "}\n",
    "paper_table = paper_table.rename(columns=rename_map)\n",
    "paper_table = paper_table.round(4)\n",
    "\n",
    "print(\"\\n{'#'*70}\")\n",
    "print(\"PAPER-READY RESULTS TABLE\")\n",
    "print(f\"{'#' * 70}\\n\")\n",
    "print(paper_table.to_string(index=False))\n",
    "\n",
    "# Save as CSV and LaTeX\n",
    "paper_table.to_csv(OUTPUT_DIR / \"paper_results.csv\", index=False)\n",
    "latex_table = paper_table.to_latex(index=False, float_format=\"%.4f\")\n",
    "with open(OUTPUT_DIR / \"paper_results.tex\", \"w\") as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(f\"\\n✓ Paper table saved: {OUTPUT_DIR / 'paper_results.csv'}\")\n",
    "print(f\"✓ LaTeX table saved: {OUTPUT_DIR / 'paper_results.tex'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a73ce0",
   "metadata": {},
   "source": [
    "## Cell 19: Export JSON Results (for sharing/archiving)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b21ea11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ JSON results saved: slim_eval_results/complete_results.json\n"
     ]
    }
   ],
   "source": [
    "# Export all results as JSON for easy sharing\n",
    "json_output = {\n",
    "    \"metadata\": {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"models\": MODELS,\n",
    "        \"precisions\": PRECISIONS,\n",
    "        \"accuracy_tasks\": ACCURACY_TASKS,\n",
    "        \"num_runs\": NUM_RUNS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "    },\n",
    "    \"results\": results_df.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "if analysis_results:\n",
    "    json_output[\"analysis\"] = analysis_df.to_dict(orient=\"records\")\n",
    "\n",
    "json_path = OUTPUT_DIR / \"complete_results.json\"\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(json_output, f, indent=2)\n",
    "\n",
    "print(f\"✓ JSON results saved: {json_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d2bca",
   "metadata": {},
   "source": [
    "## Cell 20: Generate Executive Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f3c761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SLiM-EVAL: EXECUTIVE SUMMARY REPORT\n",
      "======================================================================\n",
      "\n",
      "Generated: 2025-11-29 00:26:57\n",
      "\n",
      "Models Evaluated: 1\n",
      "Precision Modes: int8\n",
      "Total Configurations: 1\n",
      "\n",
      "======================================================================\n",
      "\n",
      "KEY FINDINGS:\n",
      "======================================================================\n",
      "\n",
      "1. FASTEST MODEL:\n",
      "   Llama-3.2-3B (int8)\n",
      "   Latency: 0.0120s\n",
      "\n",
      "2. MOST MEMORY EFFICIENT:\n",
      "   Llama-3.2-3B (int8)\n",
      "   Memory: 4202.39 MB\n",
      "\n",
      "3. HIGHEST THROUGHPUT:\n",
      "   Llama-3.2-3B (int8)\n",
      "   Throughput: 2666.08 tokens/s\n",
      "\n",
      "4. BEST AVERAGE ACCURACY:\n",
      "   Llama-3.2-3B (int8)\n",
      "   Avg Accuracy: 19.6506\n",
      "\n",
      "======================================================================\n",
      "END OF REPORT\n",
      "======================================================================\n",
      "\n",
      "✓ Executive summary saved: slim_eval_results/executive_summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Create a text report summarizing key findings\n",
    "report_lines = [\n",
    "    \"=\" * 70,\n",
    "    \"SLiM-EVAL: EXECUTIVE SUMMARY REPORT\",\n",
    "    \"=\" * 70,\n",
    "    f\"\\nGenerated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
    "    f\"\\nModels Evaluated: {len(results_df['model'].unique())}\",\n",
    "    f\"Precision Modes: {', '.join(results_df['precision'].unique())}\",\n",
    "    f\"Total Configurations: {len(results_df)}\",\n",
    "    \"\\n\" + \"=\" * 70,\n",
    "    \"\\nKEY FINDINGS:\",\n",
    "    \"=\" * 70,\n",
    "]\n",
    "\n",
    "# Find best performers\n",
    "if len(results_df) > 0:\n",
    "    # Fastest model\n",
    "    fastest = results_df.loc[results_df[\"mean_latency_s\"].idxmin()]\n",
    "    report_lines.append(f\"\\n1. FASTEST MODEL:\")\n",
    "    report_lines.append(\n",
    "        f\"   {fastest['model'].split('/')[-1]} ({fastest['precision']})\"\n",
    "    )\n",
    "    report_lines.append(f\"   Latency: {fastest['mean_latency_s']:.4f}s\")\n",
    "\n",
    "    # Most memory efficient\n",
    "    mem_efficient = results_df.loc[results_df[\"mean_peak_mem_mb\"].idxmin()]\n",
    "    report_lines.append(f\"\\n2. MOST MEMORY EFFICIENT:\")\n",
    "    report_lines.append(\n",
    "        f\"   {mem_efficient['model'].split('/')[-1]} ({mem_efficient['precision']})\"\n",
    "    )\n",
    "    report_lines.append(f\"   Memory: {mem_efficient['mean_peak_mem_mb']:.2f} MB\")\n",
    "\n",
    "    # Highest throughput\n",
    "    highest_throughput = results_df.loc[results_df[\"tokens_per_second\"].idxmax()]\n",
    "    report_lines.append(f\"\\n3. HIGHEST THROUGHPUT:\")\n",
    "    report_lines.append(\n",
    "        f\"   {highest_throughput['model'].split('/')[-1]} ({highest_throughput['precision']})\"\n",
    "    )\n",
    "    report_lines.append(\n",
    "        f\"   Throughput: {highest_throughput['tokens_per_second']:.2f} tokens/s\"\n",
    "    )\n",
    "\n",
    "    # Best accuracy (if available)\n",
    "    accuracy_cols = [col for col in results_df.columns if \"accuracy\" in col]\n",
    "    if accuracy_cols:\n",
    "        results_df[\"avg_accuracy\"] = results_df[accuracy_cols].mean(axis=1)\n",
    "        best_accuracy = results_df.loc[results_df[\"avg_accuracy\"].idxmax()]\n",
    "        report_lines.append(f\"\\n4. BEST AVERAGE ACCURACY:\")\n",
    "        report_lines.append(\n",
    "            f\"   {best_accuracy['model'].split('/')[-1]} ({best_accuracy['precision']})\"\n",
    "        )\n",
    "        report_lines.append(f\"   Avg Accuracy: {best_accuracy['avg_accuracy']:.4f}\")\n",
    "\n",
    "    # Quantization impact\n",
    "    if analysis_results:\n",
    "        report_lines.append(f\"\\n\" + \"=\" * 70)\n",
    "        report_lines.append(\"QUANTIZATION IMPACT:\")\n",
    "        report_lines.append(\"=\" * 70)\n",
    "\n",
    "        avg_speedup = analysis_df[\"speedup\"].mean()\n",
    "        avg_mem_reduction = analysis_df[\"memory_reduction_pct\"].mean()\n",
    "\n",
    "        report_lines.append(f\"\\nINT8/INT4 Quantization Effects (Average):\")\n",
    "        report_lines.append(f\"  • Speedup: {avg_speedup:.2f}x\")\n",
    "        report_lines.append(f\"  • Memory Reduction: {avg_mem_reduction:.1f}%\")\n",
    "\n",
    "        if \"energy_reduction_pct\" in analysis_df.columns:\n",
    "            avg_energy_reduction = analysis_df[\"energy_reduction_pct\"].mean()\n",
    "            report_lines.append(f\"  • Energy Reduction: {avg_energy_reduction:.1f}%\")\n",
    "\n",
    "        acc_drop_cols = [col for col in analysis_df.columns if \"acc_drop\" in col]\n",
    "        if acc_drop_cols:\n",
    "            avg_acc_drop = analysis_df[acc_drop_cols].mean().mean()\n",
    "            report_lines.append(f\"  • Average Accuracy Drop: {avg_acc_drop:.2f}%\")\n",
    "\n",
    "report_lines.append(\"\\n\" + \"=\" * 70)\n",
    "report_lines.append(\"END OF REPORT\")\n",
    "report_lines.append(\"=\" * 70)\n",
    "\n",
    "report_text = \"\\n\".join(report_lines)\n",
    "print(report_text)\n",
    "\n",
    "# Save report\n",
    "report_path = OUTPUT_DIR / \"executive_summary.txt\"\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "print(f\"\\n✓ Executive summary saved: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe55870",
   "metadata": {},
   "source": [
    "## Cell 21: Quick Single Model Test (For Debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ee03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to test a single model quickly\n",
    "# TEST_MODEL = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "# TEST_PRECISION = \"fp16\"\n",
    "#\n",
    "# print(f\"Quick test: {TEST_MODEL} in {TEST_PRECISION}\")\n",
    "# results = run_complete_benchmark(TEST_MODEL, TEST_PRECISION)\n",
    "# if results:\n",
    "#     print(\"\\nTest Results:\")\n",
    "#     for key, value in results.items():\n",
    "#         print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"Quick test cell ready (not executed)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b997f313",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary of Complete Framework\n",
    "\n",
    "### Metrics Tracked:\n",
    "1. **Latency** - Mean, median, P95, P99 inference time\n",
    "2. **Memory** - Peak and average GPU memory usage\n",
    "3. **Energy** - Power consumption and energy per query\n",
    "4. **Accuracy** - Task performance on MMLU, GSM8K, HellaSwag, etc.\n",
    "\n",
    "### Workflow:\n",
    "1. **Setup** - Configure models, precisions, benchmarks\n",
    "2. **Quantize** (optional) - Pre-quantize models with llm-compressor\n",
    "3. **Benchmark** - Run latency, memory, energy, and accuracy tests\n",
    "4. **Analyze** - Calculate trade-offs and efficiency metrics\n",
    "5. **Visualize** - Generate plots and Pareto frontiers\n",
    "6. **Report** - Export results in CSV, JSON, LaTeX formats\n",
    "\n",
    "### Next Steps:\n",
    "- Add carbon emissions tracking (multiply energy by grid carbon intensity)\n",
    "- Integrate additional benchmarks (BBH, MATH, MedQA, LegalBench)\n",
    "- Add throughput benchmarking under different batch sizes\n",
    "- Implement automated Pareto frontier analysis\n",
    "- Add statistical significance testing for accuracy differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nohup jupyter nbconvert --to notebook --execute working_file.ipynb \\\n",
    "#     --output working_file_executed.ipynb > working_file.log 2>&1 &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
