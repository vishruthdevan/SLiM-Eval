======================================================================
SLiM-EVAL: EXECUTIVE SUMMARY REPORT
======================================================================

Generated: 2025-12-17 22:28:53

Models Evaluated: 5
Precision Modes: fp16, int8, int4
Total Configurations: 13

======================================================================

KEY FINDINGS:
======================================================================

1. FASTEST MODEL:
   Llama-3.2-3B-Instruct (int8)
   Latency: 98.87 ms

2. MOST MEMORY EFFICIENT:
   gemma-3-4b-it (fp16)
   Memory: 72.64 GB

3. HIGHEST THROUGHPUT:
   Llama-3.2-3B-Instruct (int4)
   Throughput: 1936.13 tokens/s

4. BEST AVERAGE ACCURACY:
   Phi-3-mini-4k-instruct (fp16)
   Avg Accuracy: 70.07%

5. MOST ENERGY EFFICIENT:
   Phi-3-mini-4k-instruct (int4)
   Energy: 10.58 Wh

6. BEST BALANCED (Efficiency Score):
   Llama-3.2-3B-Instruct (int8)
   Latency: 98.87 ms, Accuracy: 60.17%

======================================================================
END OF REPORT
======================================================================